{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f4a82a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Driving_License</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Previously_Insured</th>\n",
       "      <th>Vehicle_Age</th>\n",
       "      <th>Vehicle_Damage</th>\n",
       "      <th>Annual_Premium</th>\n",
       "      <th>Policy_Sales_Channel</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>&gt; 2 Years</td>\n",
       "      <td>Yes</td>\n",
       "      <td>40454.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>33536.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>&gt; 2 Years</td>\n",
       "      <td>Yes</td>\n",
       "      <td>38294.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>28619.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>27496.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Gender  Age  Driving_License  Region_Code  Previously_Insured  \\\n",
       "0   1    Male   44                1         28.0                   0   \n",
       "1   2    Male   76                1          3.0                   0   \n",
       "2   3    Male   47                1         28.0                   0   \n",
       "3   4    Male   21                1         11.0                   1   \n",
       "4   5  Female   29                1         41.0                   1   \n",
       "\n",
       "  Vehicle_Age Vehicle_Damage  Annual_Premium  Policy_Sales_Channel  Vintage  \\\n",
       "0   > 2 Years            Yes         40454.0                  26.0      217   \n",
       "1    1-2 Year             No         33536.0                  26.0      183   \n",
       "2   > 2 Years            Yes         38294.0                  26.0       27   \n",
       "3    < 1 Year             No         28619.0                 152.0      203   \n",
       "4    < 1 Year             No         27496.0                 152.0       39   \n",
       "\n",
       "   Response  \n",
       "0         1  \n",
       "1         0  \n",
       "2         1  \n",
       "3         0  \n",
       "4         0  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('health_insurance.csv', nrows=100000) # Update the path\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba77b8cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99f0ac30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: [     1      2      3 ...  99998  99999 100000] unique values\n",
      "\n",
      "Gender: ['Male' 'Female'] unique values\n",
      "\n",
      "Age: [44 76 47 21 29 24 23 56 32 41 71 37 25 42 60 65 49 34 51 26 57 79 48 45\n",
      " 72 30 54 27 38 22 78 20 39 62 58 59 63 50 67 77 28 69 52 31 33 43 36 53\n",
      " 70 46 55 40 61 75 64 35 66 68 74 73 84 83 81 80 82 85] unique values\n",
      "\n",
      "Driving_License: [1 0] unique values\n",
      "\n",
      "Region_Code: [28.  3. 11. 41. 33.  6. 35. 50. 15. 45.  8. 36. 30. 26. 16. 47. 48. 19.\n",
      " 39. 23. 37.  5. 17.  2.  7. 29. 46. 27. 25. 13. 18. 20. 49. 22. 44.  0.\n",
      "  9. 31. 12. 34. 21. 10. 14. 38. 24. 40. 43. 32.  4. 51. 42.  1. 52.] unique values\n",
      "\n",
      "Previously_Insured: [0 1] unique values\n",
      "\n",
      "Vehicle_Age: ['> 2 Years' '1-2 Year' '< 1 Year'] unique values\n",
      "\n",
      "Vehicle_Damage: ['Yes' 'No'] unique values\n",
      "\n",
      "Annual_Premium: [40454. 33536. 38294. ... 23786. 49438. 49994.] unique values\n",
      "\n",
      "Policy_Sales_Channel: [ 26. 152. 160. 124.  14.  13.  30. 156. 163. 157. 122.  19.  22.  15.\n",
      " 154.  16.  52. 155.  11. 151. 125.  25.  61.   1.  86.  31. 150.  23.\n",
      "  60.  21. 121.   3. 139.  12.  29.  55.   7.  47. 127. 153.  78. 158.\n",
      "  89.  32.   8.  10. 120.  65.   4.  42.  83. 136.  24.  18.  56.  48.\n",
      " 106.  54.  93. 116.  91.  45.   9. 145. 147.  44. 109.  37. 140. 107.\n",
      " 128. 131. 114. 118. 159. 119. 105. 135.  62. 138. 129.  88.  92. 111.\n",
      " 113.  73.  36.  28.  35.  59.  53. 148. 133. 108.  64.  39.  94. 132.\n",
      "  46.  81. 103.  90.  51.  27. 146.  63.  96.  40.  66. 100.  95. 123.\n",
      "  98.  75.  69. 130. 134.  49.  97.  38.  17. 110.  80.  71. 117.  58.\n",
      "  20.  76. 104.  87.  84. 137. 126.  68.  67. 101.] unique values\n",
      "\n",
      "Vintage: [217 183  27 203  39 176 249  72  28  80  46 289 221  15  58 147 256 299\n",
      " 158 102 116 177 232  60 180  49  57 223 136 222 149 169  88 253 107 264\n",
      " 233  45 184 251 153 186  71  34  83  12 246 141 216 130 282  73 171 283\n",
      " 295 165  30 218  22  36  79  81 100  63 242 277  61 111 167  74 235 131\n",
      " 243 248 114 281  62 189 139 138 209 254 291  68  92  52  78 156 247 275\n",
      "  77 181 229 166  16  23  31 293 219  50 155  66 260  19 258 117 193 204\n",
      " 212 144 234 206 228 125  29  18  84 230  54 123 101  86  13 237  85  98\n",
      "  67 128  95  89  99 208 134 135 268 284 119 226 105 142 207 272 263  64\n",
      "  40 245 163  24 265 202 259  91 106 190 162  33 194 287 292  69 239 132\n",
      " 255 152 121 150 143 198 103 127 285 214 151 199  56  59 215 104 238 120\n",
      "  21  32 270 211 200 197  11 213  93 113 178  10 290  94 231 296  47 122\n",
      " 271 278 276  96 240 172 257 224 173 220 185  90  51 205  70 160 137 168\n",
      "  87 118 288 126 241  82 227 115 164 236 286 244 108 274 201  97  25 174\n",
      " 182 154  48  20  53  17 261  41 266  35 140 269 146 145  65 298 133 195\n",
      "  55 188  75  38  43 110  37 129 170 109 267 279 112 280  76 191  26 161\n",
      " 179 175 252  42 124 187 148 294  44 157 192 262 159 210 250  14 273 297\n",
      " 225 196] unique values\n",
      "\n",
      "Response: [1 0] unique values\n",
      "\n",
      "value_score: [26484.66012984 14196.39284351 17938.0703186  ... 16020.8014829\n",
      " 27795.05152818 18010.6619885 ] unique values\n",
      "\n",
      "Tier: ['Gold' 'Silver' 'Bronze'] unique values\n",
      "\n",
      "Customer_Note: ['Only interacts with renewal portal. No product exploration.'\n",
      " 'Customer has moderate claim history. Needs reassurance.'\n",
      " 'Customer has mid-tier health plan. Vehicle insurance could be next.'\n",
      " 'Customer clicked on ad but did not proceed. Mild interest.'\n",
      " 'Client asked about payment options.'\n",
      " 'Customer has basic coverage and no add-ons.'\n",
      " 'Responded to email with generic query. Needs tailored pitch.'\n",
      " 'Customer requested callback during working hours. Shows planning and intent.'\n",
      " 'Attended recent webinar on premium vehicle coverage. Asked multiple questions. Ready for conversion.'\n",
      " 'Customer has seasonal driving habits. Needs flexible plan.'\n",
      " 'Customer has basic plan and prefers no changes.'\n",
      " 'Customer has minimal claim history but no interest in upgrades.'\n",
      " 'Customer has mid-range sedan. Standard coverage likely.'\n",
      " 'Completed online eligibility check for vehicle insurance. Strong lead.'\n",
      " 'Responded with generic queries. No specific interest.'\n",
      " 'Asked about policy duration. Needs clarity before committing.'\n",
      " 'Customer asked about EMI options. Needs affordability pitch.'\n",
      " 'Customer has basic coverage. Upsell opportunity.'\n",
      " 'Customer asked about premium refund. Needs clarity.'\n",
      " 'Asked about roadside assistance benefits. Ready for value-added services.'\n",
      " 'Has bundled pet and health insurance. Vehicle insurance next.'\n",
      " 'Customer requested information packet.'\n",
      " 'Referred two friends for vehicle insurance. Highly engaged and influential.'\n",
      " 'Customer has mid-range vehicle. Suitable for standard plan.'\n",
      " 'Engaged in live chat for 20+ minutes discussing vehicle coverage.'\n",
      " 'Customer asked about cancellation terms. Needs confidence boost.'\n",
      " \"Responded with 'maybe later' to agent pitch.\"\n",
      " 'Clicked on SMS link but didn’t proceed. Mild interest.'\n",
      " 'Standard policy review completed.'\n",
      " 'Customer has no vehicle ownership record. Low relevance.'\n",
      " 'Requested personalized quote via mobile app. High intent signal.'\n",
      " 'Customer browsed policy terms. Needs simplified explanation.'\n",
      " 'Asked about coverage for electric vehicles. Trend-aware and proactive.'\n",
      " 'Customer has basic driving history. Standard plan suitable.'\n",
      " 'Updated contact information in system.'\n",
      " 'Downloaded comparison chart for premium plans. Wants to upgrade existing policy.'\n",
      " 'Customer asked about agent callback. Medium intent.'\n",
      " 'Scheduled callback for next week.'\n",
      " \"Responded with 'just browsing' on chatbot.\"\n",
      " 'Customer has one policy. Upsell opportunity with vehicle insurance.'\n",
      " 'Attended in-person seminar. Asked about bundling options.'\n",
      " 'Only uses app for payment. No browsing behavior.'\n",
      " 'Customer has one dependent. Family plan could appeal.'\n",
      " 'Customer has basic vehicle and no interest in upgrades.'\n",
      " 'Customer has one vehicle. Standard plan may suffice.'\n",
      " 'Low click-through rate on ads. Passive behavior.'\n",
      " 'Customer has outdated contact info. Needs verification.'\n",
      " 'Customer requested policy walkthrough. High engagement.'\n",
      " 'Customer gave testimonial for health policy. Brand advocate.'\n",
      " 'Has basic health policy. Vehicle insurance could be bundled.'\n",
      " 'Left positive feedback on health policy. Open to vehicle insurance upsell.'\n",
      " \"Responded with 'not interested' to SMS campaign.\"\n",
      " 'Customer has minimal app usage. Low tech engagement.'\n",
      " 'Customer has family health plan. Vehicle insurance for dependents possible.'\n",
      " 'Only engages with generic ads. No personalization needed.'\n",
      " 'Called to inquire about zero-depreciation add-on. Ready for upsell.'\n",
      " 'Customer has history of late renewals. Needs proactive outreach.'\n",
      " 'Responded to chatbot but dropped off. Re-engagement needed.'\n",
      " 'Asked about coverage for shared vehicles. Needs niche plan.'\n",
      " 'Asked about bundling with travel insurance. Cross-sell potential.'\n",
      " 'Customer has minimal driving history. Low insurance need.'\n",
      " 'Only responds to mandatory updates. Avoid upsell.'\n",
      " 'Responded negatively to survey. Avoid aggressive marketing.'\n",
      " 'Customer has excellent payment history. Ideal candidate for premium plan.'\n",
      " 'Requested policy in digital format. Tech-savvy and responsive.'\n",
      " 'Profile shows low income bracket. Focus on retention.'\n",
      " 'Has multiple vehicles. Interested in fleet coverage.'\n",
      " 'Customer has no dependents. Limited cross-sell options.'\n",
      " 'Customer has minimal online presence. Hard to target.'\n",
      " 'Customer has no claim history. Ideal for premium discounts.'\n",
      " 'Customer declined loyalty program. Not value-driven.'\n",
      " 'Customer has minimal feedback history. Passive user.'\n",
      " 'Asked about coverage for vintage cars. Niche interest.'\n",
      " 'Customer has history of policy lapses. Low reliability.'\n",
      " 'Customer has family coverage. Interested in adding vehicle for spouse.'\n",
      " 'Requested agent visit for policy explanation. High-touch prospect.'\n",
      " 'Customer declined agent call. Not open to discussion.'\n",
      " 'Asked about coverage for natural disasters. Risk-aware buyer.'\n",
      " 'Asked about accident coverage specifics. Likely to purchase add-ons.'\n",
      " 'Responded to SMS campaign with specific questions. Active lead.'\n",
      " 'Customer has moderate income. Needs budget-friendly options.'\n",
      " 'Profile shows low credit score. Limited premium eligibility.'\n",
      " 'Visited pricing page multiple times in one week. Sales team should reach out.'\n",
      " 'Only visited homepage. No product interaction.'\n",
      " 'Asked about coverage for theft. Needs value proposition.'\n",
      " 'Downloaded mobile app and browsed vehicle insurance section.'\n",
      " 'Opened email but didn’t click. Passive engagement.'\n",
      " 'Profile shows frequent provider switching. Low loyalty.'\n",
      " 'Requested call recording for policy explanation. Detail-oriented lead.'\n",
      " 'Customer has business vehicle. Interested in commercial coverage.'\n",
      " 'Has luxury vehicle. Interested in top-tier coverage.'\n",
      " 'Customer has minimal claim activity. Passive behavior.'\n",
      " 'Responded to survey but didn’t opt-in. Passive interest.'\n",
      " 'Only interacts during tax season. Limited insurance interest.'\n",
      " 'Customer asked about app features. Tech-friendly but undecided.'\n",
      " 'Requested quote comparison with competitor. Wants best value.'\n",
      " 'Asked about international driving coverage. Frequent traveler.'\n",
      " 'Customer browsed testimonials. Building trust.'\n",
      " 'Customer requested agent recommendation. Prefers personalized service.'\n",
      " 'Customer requested a callback to discuss bundling home and vehicle insurance. Strong cross-sell potential.'\n",
      " 'Only responds to renewal alerts. No upsell potential.'\n",
      " 'Customer has minimal driving frequency. Low coverage need.'\n",
      " 'Only clicked on unsubscribe link. Avoid future outreach.'\n",
      " 'Customer asked about app login issues. Needs support.'\n",
      " 'Customer browsed renewal options. Might upgrade.'\n",
      " 'Opened and clicked all links in promotional email. High engagement.'\n",
      " 'Has bundled travel and health insurance. Vehicle insurance is next target.'\n",
      " 'Only interacts during mandatory renewals. No upsell behavior.'\n",
      " 'Requested brochure in regional language. Shows intent and accessibility needs.'\n",
      " 'Customer browsed agent profiles. Prefers personalized service.'\n",
      " 'Customer has multiple policies. Expressed interest in loyalty rewards.'\n",
      " 'Customer has high credit score. Eligible for premium benefits.'\n",
      " 'Only responds to SMS queries. Avoid outbound calls.'\n",
      " 'Customer has corporate tie-up. Wants personal vehicle coverage.'\n",
      " 'Customer declined promotional offer. Not receptive.'\n",
      " 'Opened push notification but didn’t act. Passive lead.'\n",
      " 'Customer has basic plan and prefers offline communication.'\n",
      " 'Customer has high net worth. Prefers concierge service.'\n",
      " 'Has mid-tier engagement score. Needs targeted follow-up.'\n",
      " 'Profile shows minimal digital activity. Hard to reach.'\n",
      " 'Visited FAQ page. Might need follow-up with human agent.'\n",
      " 'Customer asked about third-party liability. Needs education.'\n",
      " 'Customer unsubscribed from marketing emails. Respect preferences.'\n",
      " 'Profile shows no referrals. Low network influence.'\n",
      " 'Requested premium calculator link. Indicates buying behavior.'\n",
      " 'Requested agent credentials. Trust-focused buyer.'\n",
      " 'Responded positively to loyalty program email. Ready for engagement.'\n",
      " 'Has mid-level engagement score. Needs nurturing.'\n",
      " 'Asked about coverage for rental cars. Occasional driver.'\n",
      " 'Clicked on comparison chart but didn’t download. Mild interest.'\n",
      " 'Customer has basic plan and no upgrades in 3 years.'\n",
      " 'Customer requested policy draft for review. Near conversion.'\n",
      " 'Customer ignored brochure delivery. No follow-up needed.'\n",
      " 'Requested brochure but hasn’t responded. Follow-up needed.'\n",
      " 'Customer ignored multiple outreach attempts. Low engagement.'\n",
      " 'Customer has leased vehicle. Needs tailored coverage.'\n",
      " 'Asked about policy renewal reminders. Needs convenience.'\n",
      " 'Has basic health plan. Vehicle insurance could be next step.'\n",
      " 'Customer has basic health plan and no interest in bundling.'\n",
      " 'Only uses mobile app for renewals. No engagement with new products.'\n",
      " 'Asked about claim limits. Needs reassurance.'\n",
      " 'Customer has basic vehicle. No interest in add-ons.'\n",
      " 'Profile shows low engagement score. Avoid proactive outreach.'\n",
      " 'Customer has teenage driver. Interested in safe-driver discounts.'\n",
      " 'Has history of switching providers. Needs retention strategy.'\n",
      " 'Customer asked about agent availability. Prefers human touch.'\n",
      " 'Has history of upgrading policies annually. Likely to convert.'\n",
      " 'Clicked on blog post about insurance myths. Curious but cautious.'\n",
      " 'Visited blog post on vehicle safety. Soft lead.'\n",
      " 'Asked about policy portability. Needs assurance.'\n",
      " 'Asked about policy exclusions. Needs transparency.'\n",
      " 'Has long-term health policy. Trusts brand.'\n",
      " 'Customer has history of early renewals. Reliable lead.'\n",
      " 'Customer asked for claim process details. Indicates serious consideration.'\n",
      " \"Responded with 'not now' to bundling offer.\"] unique values\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd \n",
    "df = pd.read_csv('synthetic_insurance_data.csv')\n",
    "for col in df.columns:\n",
    "    print(f\"{col}: {df[col].unique()} unique values\\n\")\n",
    "# df[\"Region_Code\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0050240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0]\n"
     ]
    }
   ],
   "source": [
    "a = [28.,  3., 11., 41., 33.,  6., 35., 50., 15., 45.,  8., 36., 30.,\n",
    "       26., 16., 47., 48., 19., 39., 23., 37.,  5., 17.,  2.,  7., 29.,\n",
    "       46., 27., 25., 13., 18., 20., 49., 22., 44.,  0.,  9., 31., 12.,\n",
    "       34., 21., 10., 14., 38., 24., 40., 43., 32.,  4., 51., 42.,  1.,\n",
    "       52.]\n",
    "\n",
    "a.sort()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0092fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "540165.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Annual_Premium\"].unique()\n",
    "\n",
    "max(df[\"Annual_Premium\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47dece3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3638f053",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mayur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mayur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Install required packages (run in terminal first)\n",
    "# pip install pandas numpy matplotlib seaborn scikit-learn xgboost tensorflow nltk joblib\n",
    "\n",
    "# Step 2: Import all required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from datetime import datetime\n",
    "\n",
    "# ML Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Neural Network\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# NLP\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Saving models\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Set style for plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "02434fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating tier labels with noise...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tier\n",
       "Silver    33334\n",
       "Bronze    33333\n",
       "Gold      33333\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Create Tier Label with Complexity and Noise\n",
    "print(\"\\nCreating tier labels with noise...\")\n",
    "premium_threshold = df['Annual_Premium'].quantile(0.75)\n",
    "\n",
    "# Create a more complex, continuous value score with noise\n",
    "df['value_score'] = (\n",
    "    df['Annual_Premium'] * 0.5 +\n",
    "    np.random.normal(0, 5000, len(df)) +  # Add random noise\n",
    "    (df['Response'] == 1) * 1000 +\n",
    "    (df['Previously_Insured'] == 0) * 500 -\n",
    "    df['Vintage'] * 0.1\n",
    ")\n",
    "\n",
    "# Use quantiles to create tiers\n",
    "df['Tier'] = pd.qcut(df['value_score'], q=3, labels=['Bronze', 'Silver', 'Gold'])\n",
    "\n",
    "# Check distribution\n",
    "df['Tier'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9dd562fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_notes = [\n",
    "    \"Customer requested a callback to discuss bundling home and vehicle insurance. Strong cross-sell potential.\",\n",
    "    \"Attended recent webinar on premium vehicle coverage. Asked multiple questions. Ready for conversion.\",\n",
    "    \"Referred two friends for vehicle insurance. Highly engaged and influential.\",\n",
    "    \"Downloaded comparison chart for premium plans. Wants to upgrade existing policy.\",\n",
    "    \"Requested personalized quote via mobile app. High intent signal.\",\n",
    "    \"Visited pricing page multiple times in one week. Sales team should reach out.\",\n",
    "    \"Left positive feedback on health policy. Open to vehicle insurance upsell.\",\n",
    "    \"Customer has multiple policies. Expressed interest in loyalty rewards.\",\n",
    "    \"Asked about accident coverage specifics. Likely to purchase add-ons.\",\n",
    "    \"Completed online eligibility check for vehicle insurance. Strong lead.\",\n",
    "    \"Requested agent visit for policy explanation. High-touch prospect.\",\n",
    "    \"Customer has excellent payment history. Ideal candidate for premium plan.\",\n",
    "    \"Called to inquire about zero-depreciation add-on. Ready for upsell.\",\n",
    "    \"Opened and clicked all links in promotional email. High engagement.\",\n",
    "    \"Has luxury vehicle. Interested in top-tier coverage.\",\n",
    "    \"Customer asked for claim process details. Indicates serious consideration.\",\n",
    "    \"Requested brochure in regional language. Shows intent and accessibility needs.\",\n",
    "    \"Has bundled travel and health insurance. Vehicle insurance is next target.\",\n",
    "    \"Customer gave testimonial for health policy. Brand advocate.\",\n",
    "    \"Engaged in live chat for 20+ minutes discussing vehicle coverage.\",\n",
    "    \"Requested quote comparison with competitor. Wants best value.\",\n",
    "    \"Customer has high net worth. Prefers concierge service.\",\n",
    "    \"Asked about coverage for electric vehicles. Trend-aware and proactive.\",\n",
    "    \"Downloaded mobile app and browsed vehicle insurance section.\",\n",
    "    \"Customer requested callback during working hours. Shows planning and intent.\",\n",
    "    \"Has history of upgrading policies annually. Likely to convert.\",\n",
    "    \"Responded to SMS campaign with specific questions. Active lead.\",\n",
    "    \"Customer has family coverage. Interested in adding vehicle for spouse.\",\n",
    "    \"Attended in-person seminar. Asked about bundling options.\",\n",
    "    \"Requested premium calculator link. Indicates buying behavior.\",\n",
    "    \"Customer has no claim history. Ideal for premium discounts.\",\n",
    "    \"Asked about roadside assistance benefits. Ready for value-added services.\",\n",
    "    \"Has multiple vehicles. Interested in fleet coverage.\",\n",
    "    \"Customer requested policy draft for review. Near conversion.\",\n",
    "    \"Responded positively to loyalty program email. Ready for engagement.\",\n",
    "    \"Has long-term health policy. Trusts brand.\",\n",
    "    \"Customer requested agent recommendation. Prefers personalized service.\",\n",
    "    \"Asked about coverage for vintage cars. Niche interest.\",\n",
    "    \"Customer has corporate tie-up. Wants personal vehicle coverage.\",\n",
    "    \"Requested call recording for policy explanation. Detail-oriented lead.\",\n",
    "    \"Customer has high credit score. Eligible for premium benefits.\",\n",
    "    \"Asked about international driving coverage. Frequent traveler.\",\n",
    "    \"Customer has teenage driver. Interested in safe-driver discounts.\",\n",
    "    \"Requested policy in digital format. Tech-savvy and responsive.\",\n",
    "    \"Customer has history of early renewals. Reliable lead.\",\n",
    "    \"Asked about coverage for natural disasters. Risk-aware buyer.\",\n",
    "    \"Customer requested policy walkthrough. High engagement.\",\n",
    "    \"Has bundled pet and health insurance. Vehicle insurance next.\",\n",
    "    \"Customer has leased vehicle. Needs tailored coverage.\",\n",
    "    \"Requested agent credentials. Trust-focused buyer.\",\n",
    "    \"Customer has business vehicle. Interested in commercial coverage.\"\n",
    "]\n",
    "\n",
    "\n",
    "silver_notes = [\n",
    "    \"Customer clicked on ad but did not proceed. Mild interest.\",\n",
    "    \"Asked about policy duration. Needs clarity before committing.\",\n",
    "    \"Customer has mid-tier health plan. Vehicle insurance could be next.\",\n",
    "    \"Opened email but didn’t click. Passive engagement.\",\n",
    "    \"Customer asked about EMI options. Needs affordability pitch.\",\n",
    "    \"Visited FAQ page. Might need follow-up with human agent.\",\n",
    "    \"Customer has one policy. Upsell opportunity with vehicle insurance.\",\n",
    "    \"Asked about claim limits. Needs reassurance.\",\n",
    "    \"Customer browsed testimonials. Building trust.\",\n",
    "    \"Requested brochure but hasn’t responded. Follow-up needed.\",\n",
    "    \"Customer has mid-range vehicle. Suitable for standard plan.\",\n",
    "    \"Asked about coverage for theft. Needs value proposition.\",\n",
    "    \"Customer has seasonal driving habits. Needs flexible plan.\",\n",
    "    \"Responded to chatbot but dropped off. Re-engagement needed.\",\n",
    "    \"Customer asked about cancellation terms. Needs confidence boost.\",\n",
    "    \"Has basic health policy. Vehicle insurance could be bundled.\",\n",
    "    \"Customer asked about third-party liability. Needs education.\",\n",
    "    \"Clicked on SMS link but didn’t proceed. Mild interest.\",\n",
    "    \"Customer has family health plan. Vehicle insurance for dependents possible.\",\n",
    "    \"Asked about policy portability. Needs assurance.\",\n",
    "    \"Customer has history of late renewals. Needs proactive outreach.\",\n",
    "    \"Visited blog post on vehicle safety. Soft lead.\",\n",
    "    \"Customer asked about app features. Tech-friendly but undecided.\",\n",
    "    \"Has mid-level engagement score. Needs nurturing.\",\n",
    "    \"Customer asked about agent availability. Prefers human touch.\",\n",
    "    \"Opened push notification but didn’t act. Passive lead.\",\n",
    "    \"Customer has one vehicle. Standard plan may suffice.\",\n",
    "    \"Asked about bundling with travel insurance. Cross-sell potential.\",\n",
    "    \"Customer has moderate income. Needs budget-friendly options.\",\n",
    "    \"Clicked on comparison chart but didn’t download. Mild interest.\",\n",
    "    \"Customer asked about premium refund. Needs clarity.\",\n",
    "    \"Has history of switching providers. Needs retention strategy.\",\n",
    "    \"Customer browsed policy terms. Needs simplified explanation.\",\n",
    "    \"Asked about coverage for shared vehicles. Needs niche plan.\",\n",
    "    \"Customer has basic driving history. Standard plan suitable.\",\n",
    "    \"Responded to survey but didn’t opt-in. Passive interest.\",\n",
    "    \"Customer has one dependent. Family plan could appeal.\",\n",
    "    \"Asked about policy renewal reminders. Needs convenience.\",\n",
    "    \"Customer browsed agent profiles. Prefers personalized service.\",\n",
    "    \"Has mid-tier engagement score. Needs targeted follow-up.\",\n",
    "    \"Customer asked about app login issues. Needs support.\",\n",
    "    \"Clicked on blog post about insurance myths. Curious but cautious.\",\n",
    "    \"Customer has mid-range sedan. Standard coverage likely.\",\n",
    "    \"Asked about policy exclusions. Needs transparency.\",\n",
    "    \"Customer has basic coverage. Upsell opportunity.\",\n",
    "    \"Responded to email with generic query. Needs tailored pitch.\",\n",
    "    \"Customer has moderate claim history. Needs reassurance.\",\n",
    "    \"Asked about coverage for rental cars. Occasional driver.\",\n",
    "    \"Customer browsed renewal options. Might upgrade.\",\n",
    "    \"Has basic health plan. Vehicle insurance could be next step.\",\n",
    "    \"Customer asked about agent callback. Medium intent.\"\n",
    "]\n",
    "\n",
    "\n",
    "bronze_notes = [\n",
    "    \"Customer ignored multiple outreach attempts. Low engagement.\",\n",
    "    \"Profile shows minimal digital activity. Hard to reach.\",\n",
    "    \"Customer unsubscribed from marketing emails. Respect preferences.\",\n",
    "    \"Only visited homepage. No product interaction.\",\n",
    "    \"Customer has outdated contact info. Needs verification.\",\n",
    "    \"Responded with 'not interested' to SMS campaign.\",\n",
    "    \"Customer has basic plan and no upgrades in 3 years.\",\n",
    "    \"Low click-through rate on ads. Passive behavior.\",\n",
    "    \"Customer has history of policy lapses. Low reliability.\",\n",
    "    \"Only responds to renewal alerts. No upsell potential.\",\n",
    "    \"Customer has minimal claim history but no interest in upgrades.\",\n",
    "    \"Profile shows low income bracket. Focus on retention.\",\n",
    "    \"Customer declined agent call. Not open to discussion.\",\n",
    "    \"Only uses mobile app for renewals. No engagement with new products.\",\n",
    "    \"Customer has basic vehicle. No interest in add-ons.\",\n",
    "    \"Responded negatively to survey. Avoid aggressive marketing.\",\n",
    "    \"Customer has minimal driving history. Low insurance need.\",\n",
    "    \"Only interacts during mandatory renewals. No upsell behavior.\",\n",
    "    \"Customer has no dependents. Limited cross-sell options.\",\n",
    "    \"Profile shows low credit score. Limited premium eligibility.\",\n",
    "    \"Customer ignored brochure delivery. No follow-up needed.\",\n",
    "    \"Only clicked on unsubscribe link. Avoid future outreach.\",\n",
    "    \"Customer has minimal online presence. Hard to target.\",\n",
    "    \"Responded with generic queries. No specific interest.\",\n",
    "    \"Customer has basic plan and prefers no changes.\",\n",
    "    \"Only engages with generic ads. No personalization needed.\",\n",
    "    \"Customer has no vehicle ownership record. Low relevance.\",\n",
    "    \"Profile shows frequent provider switching. Low loyalty.\",\n",
    "    \"Customer declined promotional offer. Not receptive.\",\n",
    "    \"Only responds to SMS queries. Avoid outbound calls.\",\n",
    "    \"Customer has minimal app usage. Low tech engagement.\",\n",
    "    \"Responded with 'just browsing' on chatbot.\",\n",
    "    \"Customer has basic health plan and no interest in bundling.\",\n",
    "    \"Only interacts during tax season. Limited insurance interest.\",\n",
    "    \"Customer has minimal feedback history. Passive user.\",\n",
    "    \"Profile shows no referrals. Low network influence.\",\n",
    "    \"Customer has basic coverage and no add-ons.\",\n",
    "    \"Only responds to mandatory updates. Avoid upsell.\",\n",
    "    \"Customer has minimal driving frequency. Low coverage need.\",\n",
    "    \"Responded with 'maybe later' to agent pitch.\",\n",
    "    \"Customer has basic plan and prefers offline communication.\",\n",
    "    \"Only interacts with renewal portal. No product exploration.\",\n",
    "    \"Customer has minimal claim activity. Passive behavior.\",\n",
    "    \"Profile shows low engagement score. Avoid proactive outreach.\",\n",
    "    \"Customer declined loyalty program. Not value-driven.\",\n",
    "    \"Only uses app for payment. No browsing behavior.\",\n",
    "    \"Customer has basic vehicle and no interest in upgrades.\",\n",
    "    \"Responded with 'not now' to bundling offer.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2d9eefe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ambiguous_notes = [\n",
    "    \"Customer requested information packet.\",\n",
    "    \"Standard policy review completed.\",\n",
    "    \"Client asked about payment options.\",\n",
    "    \"Scheduled callback for next week.\",\n",
    "    \"Updated contact information in system.\"\n",
    "]\n",
    "\n",
    "def generate_realistic_note(row, noise_level=0.2, ambiguous_prob=0.3):\n",
    "    \"\"\"Generate notes with noise and ambiguity\"\"\"\n",
    "    # Chance of ambiguous note\n",
    "    if np.random.random() < ambiguous_prob:\n",
    "        return np.random.choice(ambiguous_notes)\n",
    "    \n",
    "    # Chance of incorrect tier note (noise)\n",
    "    if np.random.random() < noise_level:\n",
    "        incorrect_tiers = [t for t in ['Gold', 'Silver', 'Bronze'] if t != row['Tier']]\n",
    "        chosen_tier = np.random.choice(incorrect_tiers)\n",
    "    else:\n",
    "        chosen_tier = row['Tier']\n",
    "    \n",
    "    # Return appropriate note\n",
    "    if chosen_tier == 'Gold':\n",
    "        return np.random.choice(gold_notes)\n",
    "    elif chosen_tier == 'Silver':\n",
    "        return np.random.choice(silver_notes)\n",
    "    else:\n",
    "        return np.random.choice(bronze_notes)\n",
    "\n",
    "df['Customer_Note'] = df.apply(lambda row: generate_realistic_note(row, noise_level=0.08, ambiguous_prob=0.08), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b0105250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving synthetic dataset...\n",
      "Saved: synthetic_insurance_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Save the Final Synthetic Dataset\n",
    "print(\"\\nSaving synthetic dataset...\")\n",
    "df.to_csv('synthetic_insurance_data.csv', index=False)\n",
    "print(\"Saved: synthetic_insurance_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d24db95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "95b5d492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing text data...\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Text Preprocessing\n",
    "print(\"\\nPreprocessing text data...\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    words = text.split()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "df['Processed_Note'] = df['Customer_Note'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "665e56ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing data for modeling...\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Prepare Data for Modeling\n",
    "print(\"\\nPreparing data for modeling...\")\n",
    "# Define features and target\n",
    "X = df[['Age', 'Gender', 'Region_Code', 'Driving_License', 'Previously_Insured', \n",
    "        'Vehicle_Age', 'Vehicle_Damage', 'Annual_Premium', 'Vintage', 'Processed_Note']]\n",
    "y = df['Tier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "321f42c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Separate text from structured data\n",
    "X_train_text = X_train['Processed_Note']\n",
    "X_test_text = X_test['Processed_Note']\n",
    "X_train_structured = X_train.drop('Processed_Note', axis=1)\n",
    "X_test_structured = X_test.drop('Processed_Note', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926fa821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28.,  3., 11., 41., 33.,  6., 35., 50., 15., 45.,  8., 36., 30.,\n",
       "       26., 16., 47., 48., 19., 39., 23., 37.,  5., 17.,  2.,  7., 29.,\n",
       "       46., 27., 25., 13., 18., 20., 49., 22., 44.,  0.,  9., 31., 12.,\n",
       "       34., 21., 10., 14., 38., 24., 40., 43., 32.,  4., 51., 42.,  1.,\n",
       "       52.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have 9 numerical features : ['id', 'Age', 'Driving_License', 'Region_Code', 'Previously_Insured', 'Annual_Premium', 'Policy_Sales_Channel', 'Vintage', 'Response']\n",
    "\n",
    "# We have 3 categorical features : ['Gender', 'Vehicle_Age', 'Vehicle_Damage']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d07328c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up preprocessing pipelines...\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Define Preprocessing Pipelines\n",
    "print(\"Setting up preprocessing pipelines...\")\n",
    "categorical_cols = ['Gender', 'Vehicle_Age', 'Vehicle_Damage']\n",
    "numerical_cols = ['Age','Driving_License','Region_Code','Previously_Insured', 'Annual_Premium', 'Vintage']\n",
    "\n",
    "# Structured data preprocessor\n",
    "preprocessor_structured = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Text data preprocessor\n",
    "preprocessor_text = TfidfVectorizer(max_features=500, ngram_range=(1, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d3218415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                         int64\n",
       "Gender                    object\n",
       "Age                        int64\n",
       "Driving_License            int64\n",
       "Region_Code              float64\n",
       "Previously_Insured         int64\n",
       "Vehicle_Age               object\n",
       "Vehicle_Damage            object\n",
       "Annual_Premium           float64\n",
       "Policy_Sales_Channel     float64\n",
       "Vintage                    int64\n",
       "Response                   int64\n",
       "value_score              float64\n",
       "Tier                    category\n",
       "Customer_Note             object\n",
       "Processed_Note            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c51c049c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 11 numerical features : ['id', 'Age', 'Driving_License', 'Region_Code', 'Previously_Insured', 'Annual_Premium', 'Policy_Sales_Channel', 'Vintage', 'Response', 'value_score', 'Tier']\n",
      "\n",
      "We have 5 categorical features : ['Gender', 'Vehicle_Age', 'Vehicle_Damage', 'Customer_Note', 'Processed_Note']\n"
     ]
    }
   ],
   "source": [
    "# define numerical & categorical columns\n",
    "numeric_features = [feature for feature in df.columns if df[feature].dtype != 'O']\n",
    "categorical_features = [feature for feature in df.columns if df[feature].dtype == 'O']\n",
    "\n",
    "# print columns\n",
    "print('We have {} numerical features : {}'.format(len(numeric_features), numeric_features))\n",
    "print('\\nWe have {} categorical features : {}'.format(len(categorical_features), categorical_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b93a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Example new data\n",
    "new_data = pd.DataFrame([{\n",
    "    \"Gender\": \"Male\",\n",
    "    \"Driving_License\": 1,\n",
    "    \"Previously_Insured\": 0,\n",
    "    \"Vehicle_Age\": \"< 1 Year\",\n",
    "    \"Vehicle_Damage\": \"Yes\",\n",
    "    \"Region_Code\": 28,\n",
    "    \"Age\": 35,\n",
    "    \"Annual_Premium\": 45000,\n",
    "    \"Vintage\": 120\n",
    "}])\n",
    "\n",
    "# Transform structured features\n",
    "new_data_transformed = preprocessor_structured.transform(new_data)\n",
    "\n",
    "print(\"Transformed shape:\", new_data_transformed.shape)\n",
    "print(new_data_transformed[:5])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87224dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26022bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e0d05032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming data...\n",
      "Final training features shape: (80000, 513)\n",
      "Final test features shape: (20000, 513)\n"
     ]
    }
   ],
   "source": [
    "# Step 10: Fit and Transform Data\n",
    "print(\"Transforming data...\")\n",
    "# Fit and transform structured data\n",
    "X_train_structured_processed = preprocessor_structured.fit_transform(X_train_structured)\n",
    "X_test_structured_processed = preprocessor_structured.transform(X_test_structured)\n",
    "\n",
    "# Fit and transform text data\n",
    "X_train_text_processed = preprocessor_text.fit_transform(X_train_text).toarray()\n",
    "X_test_text_processed = preprocessor_text.transform(X_test_text).toarray()\n",
    "\n",
    "# Combine features\n",
    "X_train_combined = np.hstack((X_train_structured_processed, X_train_text_processed))\n",
    "X_test_combined = np.hstack((X_test_structured_processed, X_test_text_processed))\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "print(f\"Final training features shape: {X_train_combined.shape}\")\n",
    "print(f\"Final test features shape: {X_test_combined.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6502b479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving preprocessing objects...\n",
      "Saved: artifacts/structured_preprocessor.pkl\n",
      "Saved: artifacts/text_preprocessor.pkl\n",
      "Saved: artifacts/label_encoder.pkl\n"
     ]
    }
   ],
   "source": [
    "# Step 11: Save Preprocessing Objects\n",
    "print(\"\\nSaving preprocessing objects...\")\n",
    "# Create a directory for saved models\n",
    "os.makedirs('artifacts', exist_ok=True)\n",
    "\n",
    "# Save preprocessing objects\n",
    "joblib.dump(preprocessor_structured, 'artifacts/structured_preprocessor.pkl')\n",
    "joblib.dump(preprocessor_text, 'artifacts/text_preprocessor.pkl')\n",
    "joblib.dump(label_encoder, 'artifacts/label_encoder.pkl')\n",
    "\n",
    "print(\"Saved: artifacts/structured_preprocessor.pkl\")\n",
    "print(\"Saved: artifacts/text_preprocessor.pkl\")\n",
    "print(\"Saved: artifacts/label_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6ffadb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing results storage...\n"
     ]
    }
   ],
   "source": [
    "# Step 12: Initialize Results Storage\n",
    "print(\"\\nInitializing results storage...\")\n",
    "results_df = pd.DataFrame(columns=[\n",
    "    'model_name', \n",
    "    'accuracy', \n",
    "    'precision', \n",
    "    'recall', \n",
    "    'f1_score',\n",
    "    'training_time_seconds',\n",
    "    'prediction_time_seconds',\n",
    "    'model_size_mb',\n",
    "    'timestamp'\n",
    "])\n",
    "\n",
    "trained_models = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4aa8cd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 13: Define Model Functions\n",
    "def get_classifiers():\n",
    "    \"\"\"Return a dictionary of classifiers\"\"\"\n",
    "    return {\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "        'XGBoost': XGBClassifier(random_state=42, n_estimators=100, learning_rate=0.1),\n",
    "        # 'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "        # 'SVM': SVC(kernel='rbf', random_state=42, probability=True),\n",
    "        'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000, n_jobs=-1),\n",
    "        'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5),\n",
    "        # 'Naive Bayes': GaussianNB()\n",
    "    }\n",
    "\n",
    "\n",
    "def create_neural_network(input_dim, num_classes):\n",
    "    \"\"\"Create a neural network model\"\"\"\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(input_dim,)),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "dc9aad76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_and_evaluate_model(model, model_name, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Train and evaluate a single model\"\"\"\n",
    "    print(f\"Training {model_name}...\")\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    if model_name == 'Neural Network':\n",
    "        y_train_cat = to_categorical(y_train)\n",
    "        y_test_cat = to_categorical(y_test)\n",
    "        \n",
    "        history = model.fit(\n",
    "            X_train, y_train_cat,\n",
    "            epochs=50,\n",
    "            batch_size=32,\n",
    "            validation_split=0.2,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        y_pred_proba = model.predict(X_test, verbose=1)\n",
    "        y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "        \n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "    training_time = (datetime.now() - start_time).total_seconds()\n",
    "    \n",
    "    # Calculate prediction time\n",
    "    pred_start = datetime.now()\n",
    "    _ = model.predict(X_test[:100])\n",
    "    prediction_time = (datetime.now() - pred_start).total_seconds() / 100\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    # Calculate model size\n",
    "    if model_name != 'Neural Network':\n",
    "        joblib.dump(model, 'temp_model.pkl')\n",
    "        model_size = os.path.getsize('temp_model.pkl') / (1024 * 1024)\n",
    "        os.remove('temp_model.pkl')\n",
    "    else:\n",
    "        model_size = 0\n",
    "    \n",
    "    result = {\n",
    "        'model_name': model_name,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'training_time_seconds': training_time,\n",
    "        'prediction_time_seconds': prediction_time,\n",
    "        'model_size_mb': model_size,\n",
    "        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    }\n",
    "    \n",
    "    return model, result, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f02dcc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TRAINING ALL MODELS ===\n",
      "Training Random Forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mayur\\AppData\\Local\\Temp\\ipykernel_19764\\701095100.py:11: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, pd.DataFrame([result])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Accuracy = 0.9067\n",
      "Training XGBoost...\n",
      "XGBoost: Accuracy = 0.9143\n",
      "Training Logistic Regression...\n",
      "Logistic Regression: Accuracy = 0.9157\n",
      "Training K-Nearest Neighbors...\n",
      "K-Nearest Neighbors: Accuracy = 0.8789\n"
     ]
    }
   ],
   "source": [
    "# Step 14: Train All Models\n",
    "print(\"\\n=== TRAINING ALL MODELS ===\")\n",
    "classifiers = get_classifiers()\n",
    "\n",
    "# Train traditional ML models\n",
    "for model_name, model in classifiers.items():\n",
    "    trained_model, result, y_pred = train_and_evaluate_model(\n",
    "        model, model_name, X_train_combined, X_test_combined, y_train_encoded, y_test_encoded\n",
    "    )\n",
    "    trained_models[model_name] = trained_model\n",
    "    results_df = pd.concat([results_df, pd.DataFrame([result])], ignore_index=True)\n",
    "    print(f\"{model_name}: Accuracy = {result['accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a908730b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mayur\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Neural Network...\n",
      "Epoch 1/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8429 - loss: 0.4237 - val_accuracy: 0.9053 - val_loss: 0.2812\n",
      "Epoch 2/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9085 - loss: 0.2857 - val_accuracy: 0.9091 - val_loss: 0.2707\n",
      "Epoch 3/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.2748 - val_accuracy: 0.9100 - val_loss: 0.2694\n",
      "Epoch 4/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2703 - val_accuracy: 0.9109 - val_loss: 0.2693\n",
      "Epoch 5/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2696 - val_accuracy: 0.9100 - val_loss: 0.2698\n",
      "Epoch 6/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2638 - val_accuracy: 0.9100 - val_loss: 0.2703\n",
      "Epoch 7/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2628 - val_accuracy: 0.9099 - val_loss: 0.2689\n",
      "Epoch 8/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2650 - val_accuracy: 0.9106 - val_loss: 0.2689\n",
      "Epoch 9/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9125 - loss: 0.2659 - val_accuracy: 0.9099 - val_loss: 0.2717\n",
      "Epoch 10/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9139 - loss: 0.2591 - val_accuracy: 0.9102 - val_loss: 0.2721\n",
      "Epoch 11/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9122 - loss: 0.2611 - val_accuracy: 0.9105 - val_loss: 0.2729\n",
      "Epoch 12/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9130 - loss: 0.2624 - val_accuracy: 0.9103 - val_loss: 0.2721\n",
      "Epoch 13/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9170 - loss: 0.2492 - val_accuracy: 0.9099 - val_loss: 0.2724\n",
      "Epoch 14/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.2543 - val_accuracy: 0.9091 - val_loss: 0.2717\n",
      "Epoch 15/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9159 - loss: 0.2553 - val_accuracy: 0.9093 - val_loss: 0.2728\n",
      "Epoch 16/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9143 - loss: 0.2558 - val_accuracy: 0.9087 - val_loss: 0.2749\n",
      "Epoch 17/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9144 - loss: 0.2552 - val_accuracy: 0.9075 - val_loss: 0.2735\n",
      "Epoch 18/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9160 - loss: 0.2527 - val_accuracy: 0.9103 - val_loss: 0.2746\n",
      "Epoch 19/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9147 - loss: 0.2529 - val_accuracy: 0.9096 - val_loss: 0.2740\n",
      "Epoch 20/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9162 - loss: 0.2494 - val_accuracy: 0.9091 - val_loss: 0.2741\n",
      "Epoch 21/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2530 - val_accuracy: 0.9078 - val_loss: 0.2773\n",
      "Epoch 22/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2491 - val_accuracy: 0.9088 - val_loss: 0.2761\n",
      "Epoch 23/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9169 - loss: 0.2448 - val_accuracy: 0.9097 - val_loss: 0.2805\n",
      "Epoch 24/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9162 - loss: 0.2474 - val_accuracy: 0.9082 - val_loss: 0.2783\n",
      "Epoch 25/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9160 - loss: 0.2466 - val_accuracy: 0.9072 - val_loss: 0.2783\n",
      "Epoch 26/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9162 - loss: 0.2475 - val_accuracy: 0.9086 - val_loss: 0.2771\n",
      "Epoch 27/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9170 - loss: 0.2449 - val_accuracy: 0.9079 - val_loss: 0.2787\n",
      "Epoch 28/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9161 - loss: 0.2444 - val_accuracy: 0.9087 - val_loss: 0.2801\n",
      "Epoch 29/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9169 - loss: 0.2421 - val_accuracy: 0.9079 - val_loss: 0.2824\n",
      "Epoch 30/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9167 - loss: 0.2438 - val_accuracy: 0.9084 - val_loss: 0.2810\n",
      "Epoch 31/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9169 - loss: 0.2447 - val_accuracy: 0.9076 - val_loss: 0.2821\n",
      "Epoch 32/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9185 - loss: 0.2386 - val_accuracy: 0.9067 - val_loss: 0.2818\n",
      "Epoch 33/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9172 - loss: 0.2412 - val_accuracy: 0.9084 - val_loss: 0.2859\n",
      "Epoch 34/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9197 - loss: 0.2380 - val_accuracy: 0.9069 - val_loss: 0.2858\n",
      "Epoch 35/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9194 - loss: 0.2359 - val_accuracy: 0.9064 - val_loss: 0.2829\n",
      "Epoch 36/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9196 - loss: 0.2371 - val_accuracy: 0.9070 - val_loss: 0.2846\n",
      "Epoch 37/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9187 - loss: 0.2389 - val_accuracy: 0.9070 - val_loss: 0.2860\n",
      "Epoch 38/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9188 - loss: 0.2380 - val_accuracy: 0.9067 - val_loss: 0.2898\n",
      "Epoch 39/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9204 - loss: 0.2333 - val_accuracy: 0.9062 - val_loss: 0.2873\n",
      "Epoch 40/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9192 - loss: 0.2342 - val_accuracy: 0.9076 - val_loss: 0.2853\n",
      "Epoch 41/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9206 - loss: 0.2338 - val_accuracy: 0.9063 - val_loss: 0.2880\n",
      "Epoch 42/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9185 - loss: 0.2378 - val_accuracy: 0.9075 - val_loss: 0.2879\n",
      "Epoch 43/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9196 - loss: 0.2327 - val_accuracy: 0.9072 - val_loss: 0.2918\n",
      "Epoch 44/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9189 - loss: 0.2341 - val_accuracy: 0.9080 - val_loss: 0.2891\n",
      "Epoch 45/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9193 - loss: 0.2349 - val_accuracy: 0.9078 - val_loss: 0.2878\n",
      "Epoch 46/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9210 - loss: 0.2284 - val_accuracy: 0.9074 - val_loss: 0.2889\n",
      "Epoch 47/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9209 - loss: 0.2312 - val_accuracy: 0.9073 - val_loss: 0.2902\n",
      "Epoch 48/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9216 - loss: 0.2287 - val_accuracy: 0.9074 - val_loss: 0.2950\n",
      "Epoch 49/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9187 - loss: 0.2344 - val_accuracy: 0.9075 - val_loss: 0.2936\n",
      "Epoch 50/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9208 - loss: 0.2300 - val_accuracy: 0.9071 - val_loss: 0.2889\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    }
   ],
   "source": [
    "# Train Neural Network\n",
    "nn_model = create_neural_network(X_train_combined.shape[1], len(np.unique(y_train_encoded)))\n",
    "trained_nn, nn_result, y_pred_nn = train_and_evaluate_model(\n",
    "    nn_model, 'Neural Network', X_train_combined, X_test_combined, y_train_encoded, y_test_encoded\n",
    ")\n",
    "trained_models['Neural Network'] = trained_nn\n",
    "results_df = pd.concat([results_df, pd.DataFrame([nn_result])], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be32f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save neural network and update size\n",
    "trained_nn.save('temp_nn_model.h5')\n",
    "nn_size = os.path.getsize('temp_nn_model.h5') / (1024 * 1024)\n",
    "os.remove('temp_nn_model.h5')\n",
    "results_df.loc[results_df['model_name'] == 'Neural Network', 'model_size_mb'] = nn_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae5d716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SAVING RESULTS ===\n",
      "Best model: Logistic Regression with accuracy 0.9157\n",
      "Saved: saved_models/best_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Step 15: Save Best Model and Results\n",
    "print(\"\\n=== SAVING RESULTS ===\")\n",
    "best_model_row = results_df.loc[results_df['accuracy'].idxmax()]\n",
    "best_model_name = best_model_row['model_name']\n",
    "best_model = trained_models[best_model_name]\n",
    "\n",
    "print(f\"Best model: {best_model_name} with accuracy {best_model_row['accuracy']:.4f}\")\n",
    "\n",
    "# Save the best model\n",
    "if best_model_name == 'Neural Network':\n",
    "    best_model.save('saved_models/best_model_neural_network.h5')\n",
    "    print(\"Saved: saved_models/best_model_neural_network.h5\")\n",
    "else:\n",
    "    joblib.dump(best_model, 'saved_models/best_model.pkl')\n",
    "    print(\"Saved: saved_models/best_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b08b111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all models\n",
    "for model_name, model in trained_models.items():\n",
    "    if model_name != 'Neural Network':\n",
    "        joblib.dump(model, f'saved_models/{model_name.replace(\" \", \"_\").lower()}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0833374f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: model_evaluation_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Save results to CSV\n",
    "results_df.to_csv('model_evaluation_results.csv', index=False)\n",
    "print(\"Saved: model_evaluation_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76c11d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: saved_models/training_config.json\n",
      "\n",
      "=== TRAINING COMPLETE ===\n",
      "Files created:\n",
      "- synthetic_insurance_data_with_tiers.csv\n",
      "- model_evaluation_results.csv\n",
      "- saved_models/ (directory with all preprocessing objects and models)\n",
      "- model_accuracy_comparison.png\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Step 17: Save Complete Configuration\n",
    "config = {\n",
    "    'feature_columns': numerical_cols + categorical_cols + ['Processed_Note'],\n",
    "    'target_column': 'Tier',\n",
    "    'preprocessing_steps': {\n",
    "        'structured_preprocessor': 'saved_models/structured_preprocessor.pkl',\n",
    "        'text_preprocessor': 'saved_models/text_preprocessor.pkl',\n",
    "        'label_encoder': 'saved_models/label_encoder.pkl'\n",
    "    },\n",
    "    'best_model': best_model_name,\n",
    "    'best_accuracy': best_model_row['accuracy'],\n",
    "    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "}\n",
    "\n",
    "with open('saved_models/training_config.json', 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(\"Saved: saved_models/training_config.json\")\n",
    "print(\"\\n=== TRAINING COMPLETE ===\")\n",
    "print(\"Files created:\")\n",
    "print(\"- synthetic_insurance_data_with_tiers.csv\")\n",
    "print(\"- model_evaluation_results.csv\")\n",
    "print(\"- saved_models/ (directory with all preprocessing objects and models)\")\n",
    "print(\"- model_accuracy_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bd7cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11404763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c26a49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd43ba91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e36156f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea73660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3cb2ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a1e14f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 16)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5218a436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                      0\n",
       "Gender                  0\n",
       "Age                     0\n",
       "Driving_License         0\n",
       "Region_Code             0\n",
       "Previously_Insured      0\n",
       "Vehicle_Age             0\n",
       "Vehicle_Damage          0\n",
       "Annual_Premium          0\n",
       "Policy_Sales_Channel    0\n",
       "Vintage                 0\n",
       "Response                0\n",
       "value_score             0\n",
       "Tier                    0\n",
       "Customer_Note           0\n",
       "Processed_Note          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046108eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Driving_License</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Previously_Insured</th>\n",
       "      <th>Annual_Premium</th>\n",
       "      <th>Policy_Sales_Channel</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>Response</th>\n",
       "      <th>value_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.00000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>50000.500000</td>\n",
       "      <td>38.764700</td>\n",
       "      <td>0.998040</td>\n",
       "      <td>26.445140</td>\n",
       "      <td>0.457650</td>\n",
       "      <td>30491.619450</td>\n",
       "      <td>112.438020</td>\n",
       "      <td>154.349830</td>\n",
       "      <td>0.12301</td>\n",
       "      <td>15631.676829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28867.657797</td>\n",
       "      <td>15.489417</td>\n",
       "      <td>0.044229</td>\n",
       "      <td>13.225898</td>\n",
       "      <td>0.498206</td>\n",
       "      <td>17145.025662</td>\n",
       "      <td>54.020526</td>\n",
       "      <td>83.768386</td>\n",
       "      <td>0.32845</td>\n",
       "      <td>9947.570333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2630.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-18269.453002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25000.750000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24348.750000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>9663.483118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50000.500000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31630.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>16034.851916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>75000.250000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>39411.000000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>21681.622070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>540165.000000</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>270371.227732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id            Age  Driving_License    Region_Code  \\\n",
       "count  100000.000000  100000.000000    100000.000000  100000.000000   \n",
       "mean    50000.500000      38.764700         0.998040      26.445140   \n",
       "std     28867.657797      15.489417         0.044229      13.225898   \n",
       "min         1.000000      20.000000         0.000000       0.000000   \n",
       "25%     25000.750000      25.000000         1.000000      15.000000   \n",
       "50%     50000.500000      36.000000         1.000000      28.000000   \n",
       "75%     75000.250000      49.000000         1.000000      36.000000   \n",
       "max    100000.000000      85.000000         1.000000      52.000000   \n",
       "\n",
       "       Previously_Insured  Annual_Premium  Policy_Sales_Channel  \\\n",
       "count       100000.000000   100000.000000         100000.000000   \n",
       "mean             0.457650    30491.619450            112.438020   \n",
       "std              0.498206    17145.025662             54.020526   \n",
       "min              0.000000     2630.000000              1.000000   \n",
       "25%              0.000000    24348.750000             30.000000   \n",
       "50%              0.000000    31630.000000            148.000000   \n",
       "75%              1.000000    39411.000000            152.000000   \n",
       "max              1.000000   540165.000000            163.000000   \n",
       "\n",
       "             Vintage      Response    value_score  \n",
       "count  100000.000000  100000.00000  100000.000000  \n",
       "mean      154.349830       0.12301   15631.676829  \n",
       "std        83.768386       0.32845    9947.570333  \n",
       "min        10.000000       0.00000  -18269.453002  \n",
       "25%        82.000000       0.00000    9663.483118  \n",
       "50%       154.000000       0.00000   16034.851916  \n",
       "75%       227.000000       0.00000   21681.622070  \n",
       "max       299.000000       1.00000  270371.227732  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3543f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Vehicle_Age</th>\n",
       "      <th>Vehicle_Damage</th>\n",
       "      <th>Customer_Note</th>\n",
       "      <th>Processed_Note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Male</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Client asked about payment options.</td>\n",
       "      <td>client asked payment option</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>53905</td>\n",
       "      <td>52366</td>\n",
       "      <td>50557</td>\n",
       "      <td>5097</td>\n",
       "      <td>5097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Gender Vehicle_Age Vehicle_Damage  \\\n",
       "count   100000      100000         100000   \n",
       "unique       2           3              2   \n",
       "top       Male    1-2 Year            Yes   \n",
       "freq     53905       52366          50557   \n",
       "\n",
       "                              Customer_Note               Processed_Note  \n",
       "count                                100000                       100000  \n",
       "unique                                  155                          155  \n",
       "top     Client asked about payment options.  client asked payment option  \n",
       "freq                                   5097                         5097  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='object')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed562978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                      100000\n",
       "Gender                       2\n",
       "Age                         66\n",
       "Driving_License              2\n",
       "Region_Code                 53\n",
       "Previously_Insured           2\n",
       "Vehicle_Age                  3\n",
       "Vehicle_Damage               2\n",
       "Annual_Premium           33288\n",
       "Policy_Sales_Channel       136\n",
       "Vintage                    290\n",
       "Response                     2\n",
       "value_score             100000\n",
       "Tier                         3\n",
       "Customer_Note              155\n",
       "Processed_Note             155\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a850357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Driving_License</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Previously_Insured</th>\n",
       "      <th>Annual_Premium</th>\n",
       "      <th>Policy_Sales_Channel</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>Response</th>\n",
       "      <th>value_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001554</td>\n",
       "      <td>0.005799</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.002831</td>\n",
       "      <td>-0.003331</td>\n",
       "      <td>-0.000411</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>-0.001352</td>\n",
       "      <td>-0.005044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.001554</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.076534</td>\n",
       "      <td>0.039194</td>\n",
       "      <td>-0.254040</td>\n",
       "      <td>0.070556</td>\n",
       "      <td>-0.577989</td>\n",
       "      <td>0.003573</td>\n",
       "      <td>0.109952</td>\n",
       "      <td>0.071611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Driving_License</th>\n",
       "      <td>0.005799</td>\n",
       "      <td>-0.076534</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.004765</td>\n",
       "      <td>0.013478</td>\n",
       "      <td>-0.011183</td>\n",
       "      <td>0.040134</td>\n",
       "      <td>-0.001815</td>\n",
       "      <td>0.009025</td>\n",
       "      <td>-0.009106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region_Code</th>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.039194</td>\n",
       "      <td>-0.004765</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.026874</td>\n",
       "      <td>-0.009539</td>\n",
       "      <td>-0.039907</td>\n",
       "      <td>-0.002802</td>\n",
       "      <td>0.009306</td>\n",
       "      <td>-0.009542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Previously_Insured</th>\n",
       "      <td>0.002831</td>\n",
       "      <td>-0.254040</td>\n",
       "      <td>0.013478</td>\n",
       "      <td>-0.026874</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005465</td>\n",
       "      <td>0.221301</td>\n",
       "      <td>0.004594</td>\n",
       "      <td>-0.341466</td>\n",
       "      <td>-0.031087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annual_Premium</th>\n",
       "      <td>-0.003331</td>\n",
       "      <td>0.070556</td>\n",
       "      <td>-0.011183</td>\n",
       "      <td>-0.009539</td>\n",
       "      <td>0.005465</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.114095</td>\n",
       "      <td>-0.000501</td>\n",
       "      <td>0.026168</td>\n",
       "      <td>0.862438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Policy_Sales_Channel</th>\n",
       "      <td>-0.000411</td>\n",
       "      <td>-0.577989</td>\n",
       "      <td>0.040134</td>\n",
       "      <td>-0.039907</td>\n",
       "      <td>0.221301</td>\n",
       "      <td>-0.114095</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.005843</td>\n",
       "      <td>-0.139974</td>\n",
       "      <td>-0.107192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vintage</th>\n",
       "      <td>-0.000059</td>\n",
       "      <td>0.003573</td>\n",
       "      <td>-0.001815</td>\n",
       "      <td>-0.002802</td>\n",
       "      <td>0.004594</td>\n",
       "      <td>-0.000501</td>\n",
       "      <td>-0.005843</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>-0.002952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Response</th>\n",
       "      <td>-0.001352</td>\n",
       "      <td>0.109952</td>\n",
       "      <td>0.009025</td>\n",
       "      <td>0.009306</td>\n",
       "      <td>-0.341466</td>\n",
       "      <td>0.026168</td>\n",
       "      <td>-0.139974</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.063926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value_score</th>\n",
       "      <td>-0.005044</td>\n",
       "      <td>0.071611</td>\n",
       "      <td>-0.009106</td>\n",
       "      <td>-0.009542</td>\n",
       "      <td>-0.031087</td>\n",
       "      <td>0.862438</td>\n",
       "      <td>-0.107192</td>\n",
       "      <td>-0.002952</td>\n",
       "      <td>0.063926</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id       Age  Driving_License  Region_Code  \\\n",
       "id                    1.000000 -0.001554         0.005799     0.002701   \n",
       "Age                  -0.001554  1.000000        -0.076534     0.039194   \n",
       "Driving_License       0.005799 -0.076534         1.000000    -0.004765   \n",
       "Region_Code           0.002701  0.039194        -0.004765     1.000000   \n",
       "Previously_Insured    0.002831 -0.254040         0.013478    -0.026874   \n",
       "Annual_Premium       -0.003331  0.070556        -0.011183    -0.009539   \n",
       "Policy_Sales_Channel -0.000411 -0.577989         0.040134    -0.039907   \n",
       "Vintage              -0.000059  0.003573        -0.001815    -0.002802   \n",
       "Response             -0.001352  0.109952         0.009025     0.009306   \n",
       "value_score          -0.005044  0.071611        -0.009106    -0.009542   \n",
       "\n",
       "                      Previously_Insured  Annual_Premium  \\\n",
       "id                              0.002831       -0.003331   \n",
       "Age                            -0.254040        0.070556   \n",
       "Driving_License                 0.013478       -0.011183   \n",
       "Region_Code                    -0.026874       -0.009539   \n",
       "Previously_Insured              1.000000        0.005465   \n",
       "Annual_Premium                  0.005465        1.000000   \n",
       "Policy_Sales_Channel            0.221301       -0.114095   \n",
       "Vintage                         0.004594       -0.000501   \n",
       "Response                       -0.341466        0.026168   \n",
       "value_score                    -0.031087        0.862438   \n",
       "\n",
       "                      Policy_Sales_Channel   Vintage  Response  value_score  \n",
       "id                               -0.000411 -0.000059 -0.001352    -0.005044  \n",
       "Age                              -0.577989  0.003573  0.109952     0.071611  \n",
       "Driving_License                   0.040134 -0.001815  0.009025    -0.009106  \n",
       "Region_Code                      -0.039907 -0.002802  0.009306    -0.009542  \n",
       "Previously_Insured                0.221301  0.004594 -0.341466    -0.031087  \n",
       "Annual_Premium                   -0.114095 -0.000501  0.026168     0.862438  \n",
       "Policy_Sales_Channel              1.000000 -0.005843 -0.139974    -0.107192  \n",
       "Vintage                          -0.005843  1.000000  0.001129    -0.002952  \n",
       "Response                         -0.139974  0.001129  1.000000     0.063926  \n",
       "value_score                      -0.107192 -0.002952  0.063926     1.000000  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba83043",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cca0e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ok': True, 'result': {'message_id': 3, 'from': {'id': 8304180767, 'is_bot': True, 'first_name': 'MailMinds', 'username': 'Mailminds_bot'}, 'chat': {'id': 2067973447, 'first_name': 'Mayur', 'last_name': 'Dabade', 'username': 'Mayu8862', 'type': 'private'}, 'date': 1757179438, 'text': 'Hello Mayur! 🚀 This is a test message from Python.'}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Replace with your Bot Token from BotFather\n",
    "BOT_TOKEN = \"8304180767:AAEGUvEv9TnFNoqZ0R90pASPB4p8dIjAYTk\"\n",
    "\n",
    "# Replace with your chat id\n",
    "CHAT_ID = \"2067973447\"\n",
    "\n",
    "# Message you want to send\n",
    "MESSAGE = \"Hello Mayur! 🚀 This is a test message from Python.\"\n",
    "\n",
    "# Telegram API URL\n",
    "url = f\"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage\"\n",
    "\n",
    "# Send the message\n",
    "payload = {\n",
    "    \"chat_id\": CHAT_ID,\n",
    "    \"text\": MESSAGE\n",
    "}\n",
    "\n",
    "response = requests.post(url, data=payload)\n",
    "\n",
    "# Print response for debugging\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7e64d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6d03b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
