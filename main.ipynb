{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7c74bf1",
   "metadata": {},
   "source": [
    "# üèÜ Customer Tier Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04b120d",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "Project 6: Customer Tier Classification (COIL 2000)\n",
    "\n",
    "- Objective: Classify customers into marketing tiers (e.g., Gold, Silver, Bronze) using demographic and policy data. The NLP extension involves incorporating textual data from customer interactions or applications.\n",
    "\n",
    "- Dataset: COIL 2000 dataset (structured). Text data would be synthetic (e.g., \"customer inquired about bundling home and auto insurance\").\n",
    "\n",
    "- Requirements:\n",
    "\n",
    "    Approach: Similar to Project 3. Enrich structured data with features derived from text (embeddings, topic labels, sentiment).\n",
    "\n",
    "    Modeling: Multi-class classification model (e.g., XGBoost, Random Forest, Neural Network).\n",
    "\n",
    "    Evaluation: Accuracy, F1-score (macro average)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b490e2",
   "metadata": {},
   "source": [
    "### Project Idea\n",
    "\n",
    "1. Imagine an insurance company wants to run different marketing campaigns for different types of customers. They don't want to treat a new, young customer the same way they treat a long-time, loyal customer with multiple policies.\n",
    "\n",
    "2. This project is about creating a smart system that automatically sorts customers into groups (like Gold, Silver, Bronze) based on their information.\n",
    "\n",
    "3. What you have: A list of facts about customers (their age, what kind of car they have, if they've made claims, etc.). This is the \"structured data.\"\n",
    "\n",
    "4. The cool extra step: You also get to use notes that employees write about customers, like \"Customer called, very happy with claim service\" or \"Client inquired about a discount\". This is the \"text data\" or NLP part.\n",
    "\n",
    "5. The goal: Build a model that combines both the facts and the meaning of those notes to decide which group (Gold, Silver, Bronze) a customer belongs to. The better the sorting, the more effective the company's marketing will be.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d34fc7d",
   "metadata": {},
   "source": [
    "### The Real-Life Scenario\n",
    "\n",
    "- Company: Any large insurance company (e.g., State Farm, Allstate, Geico).\n",
    "\n",
    "- Business Problem: Marketing budgets are limited. Sending expensive promotional gifts or personal agent calls to every single customer is inefficient and costly. The company wants to personalize its marketing efforts to maximize customer retention and sales.\n",
    "\n",
    "- The \"Tier\" Solution:\n",
    "The company decides to create customer tiers to target them appropriately:\n",
    "\n",
    "    1. Gold Tier: High-Value Loyalists. Long-time customers with multiple policies (e.g., home + auto + life insurance) who rarely make costly claims. Marketing Action: Send them exclusive gifts, offer a dedicated agent, and give them the highest loyalty discounts. Goal: Keep them happy so they never leave.\n",
    "\n",
    "    2. Silver Tier: Growth Potential. Customers with one policy who have a good payment history. Maybe they recently asked about adding another policy. Marketing Action: Send them targeted ads (\"Bundle and save 15%!\"). Goal: Upsell them and turn them into Gold customers.\n",
    "\n",
    "    3. Bronze Tier: New or High-Risk Customers. New customers or those with a history of late payments or frequent small claims. Marketing Action: Send them automated payment reminders and basic renewal notices. Goal: Manage cost and risk efficiently.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a22337",
   "metadata": {},
   "source": [
    "### Step 1: Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3638f053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading spaCy model...\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Install required packages (run in terminal first)\n",
    "# pip install pandas numpy matplotlib seaborn scikit-learn xgboost tensorflow nltk joblib\n",
    "\n",
    "# Step 2: Import all required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import os\n",
    "import spacy\n",
    "from datetime import datetime\n",
    "\n",
    "# ML Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Neural Network\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# NLP\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Saving models\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "# Step 3: Load spaCy model\n",
    "print(\"Loading spaCy model...\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Set style for plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc546bb0",
   "metadata": {},
   "source": [
    "### Step 2: Load and analyse dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4c075f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Driving_License</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Previously_Insured</th>\n",
       "      <th>Vehicle_Age</th>\n",
       "      <th>Vehicle_Damage</th>\n",
       "      <th>Annual_Premium</th>\n",
       "      <th>Policy_Sales_Channel</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>&gt; 2 Years</td>\n",
       "      <td>Yes</td>\n",
       "      <td>40454.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>33536.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>&gt; 2 Years</td>\n",
       "      <td>Yes</td>\n",
       "      <td>38294.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>28619.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>27496.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Gender  Age  Driving_License  Region_Code  Previously_Insured  \\\n",
       "0   1    Male   44                1         28.0                   0   \n",
       "1   2    Male   76                1          3.0                   0   \n",
       "2   3    Male   47                1         28.0                   0   \n",
       "3   4    Male   21                1         11.0                   1   \n",
       "4   5  Female   29                1         41.0                   1   \n",
       "\n",
       "  Vehicle_Age Vehicle_Damage  Annual_Premium  Policy_Sales_Channel  Vintage  \\\n",
       "0   > 2 Years            Yes         40454.0                  26.0      217   \n",
       "1    1-2 Year             No         33536.0                  26.0      183   \n",
       "2   > 2 Years            Yes         38294.0                  26.0       27   \n",
       "3    < 1 Year             No         28619.0                 152.0      203   \n",
       "4    < 1 Year             No         27496.0                 152.0       39   \n",
       "\n",
       "   Response  \n",
       "0         1  \n",
       "1         0  \n",
       "2         1  \n",
       "3         0  \n",
       "4         0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/health_insurance.csv', nrows=100000) # Update the path\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4f010f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                      0\n",
       "Gender                  0\n",
       "Age                     0\n",
       "Driving_License         0\n",
       "Region_Code             0\n",
       "Previously_Insured      0\n",
       "Vehicle_Age             0\n",
       "Vehicle_Damage          0\n",
       "Annual_Premium          0\n",
       "Policy_Sales_Channel    0\n",
       "Vintage                 0\n",
       "Response                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8dcd566a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Driving_License</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Previously_Insured</th>\n",
       "      <th>Annual_Premium</th>\n",
       "      <th>Policy_Sales_Channel</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>50000.500000</td>\n",
       "      <td>38.764700</td>\n",
       "      <td>0.998040</td>\n",
       "      <td>26.445140</td>\n",
       "      <td>0.457650</td>\n",
       "      <td>30491.619450</td>\n",
       "      <td>112.438020</td>\n",
       "      <td>154.349830</td>\n",
       "      <td>0.12301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28867.657797</td>\n",
       "      <td>15.489417</td>\n",
       "      <td>0.044229</td>\n",
       "      <td>13.225898</td>\n",
       "      <td>0.498206</td>\n",
       "      <td>17145.025662</td>\n",
       "      <td>54.020526</td>\n",
       "      <td>83.768386</td>\n",
       "      <td>0.32845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2630.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25000.750000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24348.750000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50000.500000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31630.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>75000.250000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>39411.000000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>540165.000000</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id            Age  Driving_License    Region_Code  \\\n",
       "count  100000.000000  100000.000000    100000.000000  100000.000000   \n",
       "mean    50000.500000      38.764700         0.998040      26.445140   \n",
       "std     28867.657797      15.489417         0.044229      13.225898   \n",
       "min         1.000000      20.000000         0.000000       0.000000   \n",
       "25%     25000.750000      25.000000         1.000000      15.000000   \n",
       "50%     50000.500000      36.000000         1.000000      28.000000   \n",
       "75%     75000.250000      49.000000         1.000000      36.000000   \n",
       "max    100000.000000      85.000000         1.000000      52.000000   \n",
       "\n",
       "       Previously_Insured  Annual_Premium  Policy_Sales_Channel  \\\n",
       "count       100000.000000   100000.000000         100000.000000   \n",
       "mean             0.457650    30491.619450            112.438020   \n",
       "std              0.498206    17145.025662             54.020526   \n",
       "min              0.000000     2630.000000              1.000000   \n",
       "25%              0.000000    24348.750000             30.000000   \n",
       "50%              0.000000    31630.000000            148.000000   \n",
       "75%              1.000000    39411.000000            152.000000   \n",
       "max              1.000000   540165.000000            163.000000   \n",
       "\n",
       "             Vintage      Response  \n",
       "count  100000.000000  100000.00000  \n",
       "mean      154.349830       0.12301  \n",
       "std        83.768386       0.32845  \n",
       "min        10.000000       0.00000  \n",
       "25%        82.000000       0.00000  \n",
       "50%       154.000000       0.00000  \n",
       "75%       227.000000       0.00000  \n",
       "max       299.000000       1.00000  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "dd523a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                      100000\n",
       "Gender                       2\n",
       "Age                         66\n",
       "Driving_License              2\n",
       "Region_Code                 53\n",
       "Previously_Insured           2\n",
       "Vehicle_Age                  3\n",
       "Vehicle_Damage               2\n",
       "Annual_Premium           33288\n",
       "Policy_Sales_Channel       136\n",
       "Vintage                    290\n",
       "Response                     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "558fdf02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender: ['Male' 'Female']\n",
      "\n",
      "Driving_License: [1 0]\n",
      "\n",
      "Region_Code: [28.  3. 11. 41. 33.  6. 35. 50. 15. 45.  8. 36. 30. 26. 16. 47. 48. 19.\n",
      " 39. 23. 37.  5. 17.  2.  7. 29. 46. 27. 25. 13. 18. 20. 49. 22. 44.  0.\n",
      "  9. 31. 12. 34. 21. 10. 14. 38. 24. 40. 43. 32.  4. 51. 42.  1. 52.]\n",
      "\n",
      "Previously_Insured: [0 1]\n",
      "\n",
      "Vehicle_Age: ['> 2 Years' '1-2 Year' '< 1 Year']\n",
      "\n",
      "Vehicle_Damage: ['Yes' 'No']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns = ['Gender', 'Driving_License', 'Region_Code',\n",
    "       'Previously_Insured', 'Vehicle_Age', 'Vehicle_Damage']\n",
    "\n",
    "for col in columns:\n",
    "    print(f\"{col}: {df[col].unique()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d700ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "668938e6",
   "metadata": {},
   "source": [
    "### Step 3: Create Tier Label with Complexity and Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02434fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating tier labels with noise...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tier\n",
       "Silver    33334\n",
       "Bronze    33333\n",
       "Gold      33333\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Create Tier Label with Complexity and Noise\n",
    "print(\"\\nCreating tier labels with noise...\")\n",
    "premium_threshold = df['Annual_Premium'].quantile(0.75)\n",
    "\n",
    "# Create a more complex, continuous value score with noise\n",
    "df['value_score'] = (\n",
    "    df['Annual_Premium'] * 0.5 +\n",
    "    np.random.normal(0, 5000, len(df)) +  # Add random noise\n",
    "    (df['Response'] == 1) * 1000 +\n",
    "    (df['Previously_Insured'] == 0) * 500 -\n",
    "    df['Vintage'] * 0.1\n",
    ")\n",
    "\n",
    "# Use quantiles to create tiers\n",
    "df['Tier'] = pd.qcut(df['value_score'], q=3, labels=['Bronze', 'Silver', 'Gold'])\n",
    "\n",
    "# Check distribution\n",
    "df['Tier'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22d7d39",
   "metadata": {},
   "source": [
    "### Step 4: Add customer Notes coulmn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd562fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_notes = [\n",
    "    \"Customer requested a callback to discuss bundling home and vehicle insurance. Strong cross-sell potential.\",\n",
    "    \"Attended recent webinar on premium vehicle coverage. Asked multiple questions. Ready for conversion.\",\n",
    "    \"Referred two friends for vehicle insurance. Highly engaged and influential.\",\n",
    "    \"Downloaded comparison chart for premium plans. Wants to upgrade existing policy.\",\n",
    "    \"Requested personalized quote via mobile app. High intent signal.\",\n",
    "    \"Visited pricing page multiple times in one week. Sales team should reach out.\",\n",
    "    \"Left positive feedback on health policy. Open to vehicle insurance upsell.\",\n",
    "    \"Customer has multiple policies. Expressed interest in loyalty rewards.\",\n",
    "    \"Asked about accident coverage specifics. Likely to purchase add-ons.\",\n",
    "    \"Completed online eligibility check for vehicle insurance. Strong lead.\",\n",
    "    \"Requested agent visit for policy explanation. High-touch prospect.\",\n",
    "    \"Customer has excellent payment history. Ideal candidate for premium plan.\",\n",
    "    \"Called to inquire about zero-depreciation add-on. Ready for upsell.\",\n",
    "    \"Opened and clicked all links in promotional email. High engagement.\",\n",
    "    \"Has luxury vehicle. Interested in top-tier coverage.\",\n",
    "    \"Customer asked for claim process details. Indicates serious consideration.\",\n",
    "    \"Requested brochure in regional language. Shows intent and accessibility needs.\",\n",
    "    \"Has bundled travel and health insurance. Vehicle insurance is next target.\",\n",
    "    \"Customer gave testimonial for health policy. Brand advocate.\",\n",
    "    \"Engaged in live chat for 20+ minutes discussing vehicle coverage.\",\n",
    "    \"Requested quote comparison with competitor. Wants best value.\",\n",
    "    \"Customer has high net worth. Prefers concierge service.\",\n",
    "    \"Asked about coverage for electric vehicles. Trend-aware and proactive.\",\n",
    "    \"Downloaded mobile app and browsed vehicle insurance section.\",\n",
    "    \"Customer requested callback during working hours. Shows planning and intent.\",\n",
    "    \"Has history of upgrading policies annually. Likely to convert.\",\n",
    "    \"Responded to SMS campaign with specific questions. Active lead.\",\n",
    "    \"Customer has family coverage. Interested in adding vehicle for spouse.\",\n",
    "    \"Attended in-person seminar. Asked about bundling options.\",\n",
    "    \"Requested premium calculator link. Indicates buying behavior.\",\n",
    "    \"Customer has no claim history. Ideal for premium discounts.\",\n",
    "    \"Asked about roadside assistance benefits. Ready for value-added services.\",\n",
    "    \"Has multiple vehicles. Interested in fleet coverage.\",\n",
    "    \"Customer requested policy draft for review. Near conversion.\",\n",
    "    \"Responded positively to loyalty program email. Ready for engagement.\",\n",
    "    \"Has long-term health policy. Trusts brand.\",\n",
    "    \"Customer requested agent recommendation. Prefers personalized service.\",\n",
    "    \"Asked about coverage for vintage cars. Niche interest.\",\n",
    "    \"Customer has corporate tie-up. Wants personal vehicle coverage.\",\n",
    "    \"Requested call recording for policy explanation. Detail-oriented lead.\",\n",
    "    \"Customer has high credit score. Eligible for premium benefits.\",\n",
    "    \"Asked about international driving coverage. Frequent traveler.\",\n",
    "    \"Customer has teenage driver. Interested in safe-driver discounts.\",\n",
    "    \"Requested policy in digital format. Tech-savvy and responsive.\",\n",
    "    \"Customer has history of early renewals. Reliable lead.\",\n",
    "    \"Asked about coverage for natural disasters. Risk-aware buyer.\",\n",
    "    \"Customer requested policy walkthrough. High engagement.\",\n",
    "    \"Has bundled pet and health insurance. Vehicle insurance next.\",\n",
    "    \"Customer has leased vehicle. Needs tailored coverage.\",\n",
    "    \"Requested agent credentials. Trust-focused buyer.\",\n",
    "    \"Customer has business vehicle. Interested in commercial coverage.\"\n",
    "]\n",
    "\n",
    "\n",
    "silver_notes = [\n",
    "    \"Customer clicked on ad but did not proceed. Mild interest.\",\n",
    "    \"Asked about policy duration. Needs clarity before committing.\",\n",
    "    \"Customer has mid-tier health plan. Vehicle insurance could be next.\",\n",
    "    \"Opened email but didn‚Äôt click. Passive engagement.\",\n",
    "    \"Customer asked about EMI options. Needs affordability pitch.\",\n",
    "    \"Visited FAQ page. Might need follow-up with human agent.\",\n",
    "    \"Customer has one policy. Upsell opportunity with vehicle insurance.\",\n",
    "    \"Asked about claim limits. Needs reassurance.\",\n",
    "    \"Customer browsed testimonials. Building trust.\",\n",
    "    \"Requested brochure but hasn‚Äôt responded. Follow-up needed.\",\n",
    "    \"Customer has mid-range vehicle. Suitable for standard plan.\",\n",
    "    \"Asked about coverage for theft. Needs value proposition.\",\n",
    "    \"Customer has seasonal driving habits. Needs flexible plan.\",\n",
    "    \"Responded to chatbot but dropped off. Re-engagement needed.\",\n",
    "    \"Customer asked about cancellation terms. Needs confidence boost.\",\n",
    "    \"Has basic health policy. Vehicle insurance could be bundled.\",\n",
    "    \"Customer asked about third-party liability. Needs education.\",\n",
    "    \"Clicked on SMS link but didn‚Äôt proceed. Mild interest.\",\n",
    "    \"Customer has family health plan. Vehicle insurance for dependents possible.\",\n",
    "    \"Asked about policy portability. Needs assurance.\",\n",
    "    \"Customer has history of late renewals. Needs proactive outreach.\",\n",
    "    \"Visited blog post on vehicle safety. Soft lead.\",\n",
    "    \"Customer asked about app features. Tech-friendly but undecided.\",\n",
    "    \"Has mid-level engagement score. Needs nurturing.\",\n",
    "    \"Customer asked about agent availability. Prefers human touch.\",\n",
    "    \"Opened push notification but didn‚Äôt act. Passive lead.\",\n",
    "    \"Customer has one vehicle. Standard plan may suffice.\",\n",
    "    \"Asked about bundling with travel insurance. Cross-sell potential.\",\n",
    "    \"Customer has moderate income. Needs budget-friendly options.\",\n",
    "    \"Clicked on comparison chart but didn‚Äôt download. Mild interest.\",\n",
    "    \"Customer asked about premium refund. Needs clarity.\",\n",
    "    \"Has history of switching providers. Needs retention strategy.\",\n",
    "    \"Customer browsed policy terms. Needs simplified explanation.\",\n",
    "    \"Asked about coverage for shared vehicles. Needs niche plan.\",\n",
    "    \"Customer has basic driving history. Standard plan suitable.\",\n",
    "    \"Responded to survey but didn‚Äôt opt-in. Passive interest.\",\n",
    "    \"Customer has one dependent. Family plan could appeal.\",\n",
    "    \"Asked about policy renewal reminders. Needs convenience.\",\n",
    "    \"Customer browsed agent profiles. Prefers personalized service.\",\n",
    "    \"Has mid-tier engagement score. Needs targeted follow-up.\",\n",
    "    \"Customer asked about app login issues. Needs support.\",\n",
    "    \"Clicked on blog post about insurance myths. Curious but cautious.\",\n",
    "    \"Customer has mid-range sedan. Standard coverage likely.\",\n",
    "    \"Asked about policy exclusions. Needs transparency.\",\n",
    "    \"Customer has basic coverage. Upsell opportunity.\",\n",
    "    \"Responded to email with generic query. Needs tailored pitch.\",\n",
    "    \"Customer has moderate claim history. Needs reassurance.\",\n",
    "    \"Asked about coverage for rental cars. Occasional driver.\",\n",
    "    \"Customer browsed renewal options. Might upgrade.\",\n",
    "    \"Has basic health plan. Vehicle insurance could be next step.\",\n",
    "    \"Customer asked about agent callback. Medium intent.\"\n",
    "]\n",
    "\n",
    "\n",
    "bronze_notes = [\n",
    "    \"Customer ignored multiple outreach attempts. Low engagement.\",\n",
    "    \"Profile shows minimal digital activity. Hard to reach.\",\n",
    "    \"Customer unsubscribed from marketing emails. Respect preferences.\",\n",
    "    \"Only visited homepage. No product interaction.\",\n",
    "    \"Customer has outdated contact info. Needs verification.\",\n",
    "    \"Responded with 'not interested' to SMS campaign.\",\n",
    "    \"Customer has basic plan and no upgrades in 3 years.\",\n",
    "    \"Low click-through rate on ads. Passive behavior.\",\n",
    "    \"Customer has history of policy lapses. Low reliability.\",\n",
    "    \"Only responds to renewal alerts. No upsell potential.\",\n",
    "    \"Customer has minimal claim history but no interest in upgrades.\",\n",
    "    \"Profile shows low income bracket. Focus on retention.\",\n",
    "    \"Customer declined agent call. Not open to discussion.\",\n",
    "    \"Only uses mobile app for renewals. No engagement with new products.\",\n",
    "    \"Customer has basic vehicle. No interest in add-ons.\",\n",
    "    \"Responded negatively to survey. Avoid aggressive marketing.\",\n",
    "    \"Customer has minimal driving history. Low insurance need.\",\n",
    "    \"Only interacts during mandatory renewals. No upsell behavior.\",\n",
    "    \"Customer has no dependents. Limited cross-sell options.\",\n",
    "    \"Profile shows low credit score. Limited premium eligibility.\",\n",
    "    \"Customer ignored brochure delivery. No follow-up needed.\",\n",
    "    \"Only clicked on unsubscribe link. Avoid future outreach.\",\n",
    "    \"Customer has minimal online presence. Hard to target.\",\n",
    "    \"Responded with generic queries. No specific interest.\",\n",
    "    \"Customer has basic plan and prefers no changes.\",\n",
    "    \"Only engages with generic ads. No personalization needed.\",\n",
    "    \"Customer has no vehicle ownership record. Low relevance.\",\n",
    "    \"Profile shows frequent provider switching. Low loyalty.\",\n",
    "    \"Customer declined promotional offer. Not receptive.\",\n",
    "    \"Only responds to SMS queries. Avoid outbound calls.\",\n",
    "    \"Customer has minimal app usage. Low tech engagement.\",\n",
    "    \"Responded with 'just browsing' on chatbot.\",\n",
    "    \"Customer has basic health plan and no interest in bundling.\",\n",
    "    \"Only interacts during tax season. Limited insurance interest.\",\n",
    "    \"Customer has minimal feedback history. Passive user.\",\n",
    "    \"Profile shows no referrals. Low network influence.\",\n",
    "    \"Customer has basic coverage and no add-ons.\",\n",
    "    \"Only responds to mandatory updates. Avoid upsell.\",\n",
    "    \"Customer has minimal driving frequency. Low coverage need.\",\n",
    "    \"Responded with 'maybe later' to agent pitch.\",\n",
    "    \"Customer has basic plan and prefers offline communication.\",\n",
    "    \"Only interacts with renewal portal. No product exploration.\",\n",
    "    \"Customer has minimal claim activity. Passive behavior.\",\n",
    "    \"Profile shows low engagement score. Avoid proactive outreach.\",\n",
    "    \"Customer declined loyalty program. Not value-driven.\",\n",
    "    \"Only uses app for payment. No browsing behavior.\",\n",
    "    \"Customer has basic vehicle and no interest in upgrades.\",\n",
    "    \"Responded with 'not now' to bundling offer.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2d9eefe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ambiguous_notes = [\n",
    "    \"Customer requested information packet.\",\n",
    "    \"Standard policy review completed.\",\n",
    "    \"Client asked about payment options.\",\n",
    "    \"Scheduled callback for next week.\",\n",
    "    \"Updated contact information in system.\"\n",
    "]\n",
    "\n",
    "def generate_realistic_note(row, noise_level=0.2, ambiguous_prob=0.3):\n",
    "    \"\"\"Generate notes with noise and ambiguity\"\"\"\n",
    "    # Chance of ambiguous note\n",
    "    if np.random.random() < ambiguous_prob:\n",
    "        return np.random.choice(ambiguous_notes)\n",
    "    \n",
    "    # Chance of incorrect tier note (noise)\n",
    "    if np.random.random() < noise_level:\n",
    "        incorrect_tiers = [t for t in ['Gold', 'Silver', 'Bronze'] if t != row['Tier']]\n",
    "        chosen_tier = np.random.choice(incorrect_tiers)\n",
    "    else:\n",
    "        chosen_tier = row['Tier']\n",
    "    \n",
    "    # Return appropriate note\n",
    "    if chosen_tier == 'Gold':\n",
    "        return np.random.choice(gold_notes)\n",
    "    elif chosen_tier == 'Silver':\n",
    "        return np.random.choice(silver_notes)\n",
    "    else:\n",
    "        return np.random.choice(bronze_notes)\n",
    "\n",
    "df['Customer_Note'] = df.apply(lambda row: generate_realistic_note(row, noise_level=0.08, ambiguous_prob=0.08), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3523a5",
   "metadata": {},
   "source": [
    "#### Preprocess customer notes column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3e996f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_text_with_spacy(text):\n",
    "    \"\"\"Preprocess text using spaCy\"\"\"\n",
    "    doc = nlp(text.lower())\n",
    "    \n",
    "    # Extract tokens: only alphabetic, not stopwords, not punctuation, length > 2\n",
    "    tokens = [\n",
    "        token.lemma_.lower() for token in doc \n",
    "        if not token.is_stop \n",
    "        and not token.is_punct \n",
    "        and token.is_alpha \n",
    "        and len(token) > 2\n",
    "    ]\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply spaCy preprocessing\n",
    "df['Processed_Note'] = df['Customer_Note'].apply(preprocess_text_with_spacy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3d7eab",
   "metadata": {},
   "source": [
    "### Step 5: Save the Final Synthetic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0105250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving synthetic dataset...\n",
      "Saved: synthetic_insurance_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Save the Final Synthetic Dataset\n",
    "print(\"\\nSaving synthetic dataset...\")\n",
    "df.to_csv('data/synthetic_insurance_data.csv', index=False)\n",
    "print(\"Saved: synthetic_insurance_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d24db95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Driving_License</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Previously_Insured</th>\n",
       "      <th>Vehicle_Age</th>\n",
       "      <th>Vehicle_Damage</th>\n",
       "      <th>Annual_Premium</th>\n",
       "      <th>Policy_Sales_Channel</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>Response</th>\n",
       "      <th>value_score</th>\n",
       "      <th>Tier</th>\n",
       "      <th>Customer_Note</th>\n",
       "      <th>Processed_Note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>&gt; 2 Years</td>\n",
       "      <td>Yes</td>\n",
       "      <td>40454.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "      <td>14732.376131</td>\n",
       "      <td>Silver</td>\n",
       "      <td>Customer has seasonal driving habits. Needs fl...</td>\n",
       "      <td>customer seasonal driving habit need flexible ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>33536.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "      <td>16863.337010</td>\n",
       "      <td>Silver</td>\n",
       "      <td>Customer declined agent call. Not open to disc...</td>\n",
       "      <td>customer decline agent open discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>&gt; 2 Years</td>\n",
       "      <td>Yes</td>\n",
       "      <td>38294.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>23212.907992</td>\n",
       "      <td>Gold</td>\n",
       "      <td>Has luxury vehicle. Interested in top-tier cov...</td>\n",
       "      <td>luxury vehicle interested tier coverage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>28619.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>14530.572061</td>\n",
       "      <td>Silver</td>\n",
       "      <td>Visited pricing page multiple times in one wee...</td>\n",
       "      <td>visit pricing page multiple time week sale tea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>27496.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>12133.246629</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>Scheduled callback for next week.</td>\n",
       "      <td>schedule callback week</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Gender  Age  Driving_License  Region_Code  Previously_Insured  \\\n",
       "0   1    Male   44                1         28.0                   0   \n",
       "1   2    Male   76                1          3.0                   0   \n",
       "2   3    Male   47                1         28.0                   0   \n",
       "3   4    Male   21                1         11.0                   1   \n",
       "4   5  Female   29                1         41.0                   1   \n",
       "\n",
       "  Vehicle_Age Vehicle_Damage  Annual_Premium  Policy_Sales_Channel  Vintage  \\\n",
       "0   > 2 Years            Yes         40454.0                  26.0      217   \n",
       "1    1-2 Year             No         33536.0                  26.0      183   \n",
       "2   > 2 Years            Yes         38294.0                  26.0       27   \n",
       "3    < 1 Year             No         28619.0                 152.0      203   \n",
       "4    < 1 Year             No         27496.0                 152.0       39   \n",
       "\n",
       "   Response   value_score    Tier  \\\n",
       "0         1  14732.376131  Silver   \n",
       "1         0  16863.337010  Silver   \n",
       "2         1  23212.907992    Gold   \n",
       "3         0  14530.572061  Silver   \n",
       "4         0  12133.246629  Bronze   \n",
       "\n",
       "                                       Customer_Note  \\\n",
       "0  Customer has seasonal driving habits. Needs fl...   \n",
       "1  Customer declined agent call. Not open to disc...   \n",
       "2  Has luxury vehicle. Interested in top-tier cov...   \n",
       "3  Visited pricing page multiple times in one wee...   \n",
       "4                  Scheduled callback for next week.   \n",
       "\n",
       "                                      Processed_Note  \n",
       "0  customer seasonal driving habit need flexible ...  \n",
       "1             customer decline agent open discussion  \n",
       "2            luxury vehicle interested tier coverage  \n",
       "3  visit pricing page multiple time week sale tea...  \n",
       "4                             schedule callback week  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/synthetic_insurance_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184510b7",
   "metadata": {},
   "source": [
    "### Step 6: Prepare Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "665e56ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing data for modeling...\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Prepare Data for Modeling\n",
    "print(\"\\nPreparing data for modeling...\")\n",
    "# Define features and target\n",
    "X = df[['Age', 'Gender', 'Region_Code', 'Driving_License', 'Previously_Insured', \n",
    "        'Vehicle_Age', 'Vehicle_Damage', 'Annual_Premium', 'Vintage', 'Processed_Note']]\n",
    "y = df['Tier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "321f42c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Separate text from structured data\n",
    "X_train_text = X_train['Processed_Note']\n",
    "X_test_text = X_test['Processed_Note']\n",
    "X_train_structured = X_train.drop('Processed_Note', axis=1)\n",
    "X_test_structured = X_test.drop('Processed_Note', axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75aab13d",
   "metadata": {},
   "source": [
    "### Step 7: Define Preprocessing Pipelines and fit and trnsform dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07328c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up preprocessing pipelines...\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Define Preprocessing Pipelines\n",
    "print(\"Setting up preprocessing pipelines...\")\n",
    "categorical_cols = ['Gender', 'Vehicle_Age', 'Vehicle_Damage']\n",
    "numerical_cols = ['Age','Driving_License','Region_Code','Previously_Insured', 'Annual_Premium', 'Vintage']\n",
    "\n",
    "# Structured data preprocessor\n",
    "preprocessor_structured = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Text data preprocessor\n",
    "preprocessor_text = TfidfVectorizer(max_features=500, ngram_range=(1, 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d05032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming data...\n",
      "Final training features shape: (80000, 513)\n",
      "Final test features shape: (20000, 513)\n"
     ]
    }
   ],
   "source": [
    "print(\"Transforming data...\")\n",
    "# Fit and transform structured data\n",
    "X_train_structured_processed = preprocessor_structured.fit_transform(X_train_structured)\n",
    "X_test_structured_processed = preprocessor_structured.transform(X_test_structured)\n",
    "\n",
    "# Fit and transform text data\n",
    "X_train_text_processed = preprocessor_text.fit_transform(X_train_text).toarray()\n",
    "X_test_text_processed = preprocessor_text.transform(X_test_text).toarray()\n",
    "\n",
    "# Combine features\n",
    "X_train_combined = np.hstack((X_train_structured_processed, X_train_text_processed))\n",
    "X_test_combined = np.hstack((X_test_structured_processed, X_test_text_processed))\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "print(f\"Final training features shape: {X_train_combined.shape}\")\n",
    "print(f\"Final test features shape: {X_test_combined.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660aa9c0",
   "metadata": {},
   "source": [
    "### Step 8: Save Preprocessing Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6502b479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving preprocessing objects...\n",
      "Saved: artifacts/structured_preprocessor.pkl\n",
      "Saved: artifacts/text_preprocessor.pkl\n",
      "Saved: artifacts/label_encoder.pkl\n"
     ]
    }
   ],
   "source": [
    "# Step 11: Save Preprocessing Objects\n",
    "print(\"\\nSaving preprocessing objects...\")\n",
    "# Create a directory for saved models\n",
    "os.makedirs('artifacts', exist_ok=True)\n",
    "\n",
    "# Save preprocessing objects\n",
    "joblib.dump(preprocessor_structured, 'artifacts/structured_preprocessor.pkl')\n",
    "joblib.dump(preprocessor_text, 'artifacts/text_preprocessor.pkl')\n",
    "joblib.dump(label_encoder, 'artifacts/label_encoder.pkl')\n",
    "\n",
    "print(\"Saved: artifacts/structured_preprocessor.pkl\")\n",
    "print(\"Saved: artifacts/text_preprocessor.pkl\")\n",
    "print(\"Saved: artifacts/label_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0eaadeb",
   "metadata": {},
   "source": [
    "### Step 9: Train diiferent ML and neural network Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffadb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing results storage...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nInitializing results storage...\")\n",
    "results_df = pd.DataFrame(columns=[\n",
    "    'model_name', \n",
    "    'accuracy', \n",
    "    'precision', \n",
    "    'recall', \n",
    "    'f1_score',\n",
    "    'training_time_seconds',\n",
    "    'prediction_time_seconds',\n",
    "    'model_size_mb',\n",
    "    'timestamp'\n",
    "])\n",
    "\n",
    "trained_models = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa8cd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_classifiers():\n",
    "    \"\"\"Return a dictionary of classifiers\"\"\"\n",
    "    return {\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "        'XGBoost': XGBClassifier(random_state=42, n_estimators=100, learning_rate=0.1),\n",
    "        'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000, n_jobs=-1),\n",
    "        'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5),\n",
    "    }\n",
    "\n",
    "\n",
    "def create_neural_network(input_dim, num_classes):\n",
    "    \"\"\"Create a neural network model\"\"\"\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(input_dim,)),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dc9aad76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_and_evaluate_model(model, model_name, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Train and evaluate a single model\"\"\"\n",
    "    print(f\"Training {model_name}...\")\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    if model_name == 'Neural Network':\n",
    "        y_train_cat = to_categorical(y_train)\n",
    "        y_test_cat = to_categorical(y_test)\n",
    "        \n",
    "        history = model.fit(\n",
    "            X_train, y_train_cat,\n",
    "            epochs=50,\n",
    "            batch_size=32,\n",
    "            validation_split=0.2,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        y_pred_proba = model.predict(X_test, verbose=1)\n",
    "        y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "        \n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "    training_time = (datetime.now() - start_time).total_seconds()\n",
    "    \n",
    "    # Calculate prediction time\n",
    "    pred_start = datetime.now()\n",
    "    _ = model.predict(X_test[:100])\n",
    "    prediction_time = (datetime.now() - pred_start).total_seconds() / 100\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    # Calculate model size\n",
    "    if model_name != 'Neural Network':\n",
    "        joblib.dump(model, 'temp_model.pkl')\n",
    "        model_size = os.path.getsize('temp_model.pkl') / (1024 * 1024)\n",
    "        os.remove('temp_model.pkl')\n",
    "    else:\n",
    "        model_size = 0\n",
    "    \n",
    "    result = {\n",
    "        'model_name': model_name,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'training_time_seconds': training_time,\n",
    "        'prediction_time_seconds': prediction_time,\n",
    "        'model_size_mb': model_size,\n",
    "        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    }\n",
    "    \n",
    "    return model, result, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02dcc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TRAINING ALL MODELS ===\n",
      "Training Random Forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mayur\\AppData\\Local\\Temp\\ipykernel_6972\\701095100.py:11: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, pd.DataFrame([result])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Accuracy = 0.9003\n",
      "Training XGBoost...\n",
      "XGBoost: Accuracy = 0.9102\n",
      "Training Logistic Regression...\n",
      "Logistic Regression: Accuracy = 0.9114\n",
      "Training K-Nearest Neighbors...\n",
      "K-Nearest Neighbors: Accuracy = 0.8710\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n=== TRAINING ALL MODELS ===\")\n",
    "classifiers = get_classifiers()\n",
    "\n",
    "# Train traditional ML models\n",
    "for model_name, model in classifiers.items():\n",
    "    trained_model, result, y_pred = train_and_evaluate_model(\n",
    "        model, model_name, X_train_combined, X_test_combined, y_train_encoded, y_test_encoded\n",
    "    )\n",
    "    trained_models[model_name] = trained_model\n",
    "    results_df = pd.concat([results_df, pd.DataFrame([result])], ignore_index=True)\n",
    "    print(f\"{model_name}: Accuracy = {result['accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a908730b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mayur\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Neural Network...\n",
      "Epoch 1/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8295 - loss: 0.4354 - val_accuracy: 0.9089 - val_loss: 0.2788\n",
      "Epoch 2/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9123 - loss: 0.2756 - val_accuracy: 0.9098 - val_loss: 0.2743\n",
      "Epoch 3/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9116 - loss: 0.2730 - val_accuracy: 0.9103 - val_loss: 0.2769\n",
      "Epoch 4/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9133 - loss: 0.2690 - val_accuracy: 0.9105 - val_loss: 0.2729\n",
      "Epoch 5/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9138 - loss: 0.2664 - val_accuracy: 0.9100 - val_loss: 0.2749\n",
      "Epoch 6/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9143 - loss: 0.2655 - val_accuracy: 0.9092 - val_loss: 0.2729\n",
      "Epoch 7/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9166 - loss: 0.2597 - val_accuracy: 0.9094 - val_loss: 0.2748\n",
      "Epoch 8/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9154 - loss: 0.2589 - val_accuracy: 0.9088 - val_loss: 0.2730\n",
      "Epoch 9/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9174 - loss: 0.2567 - val_accuracy: 0.9097 - val_loss: 0.2736\n",
      "Epoch 10/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9168 - loss: 0.2543 - val_accuracy: 0.9093 - val_loss: 0.2736\n",
      "Epoch 11/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9148 - loss: 0.2581 - val_accuracy: 0.9109 - val_loss: 0.2736\n",
      "Epoch 12/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9170 - loss: 0.2564 - val_accuracy: 0.9067 - val_loss: 0.2819\n",
      "Epoch 13/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9176 - loss: 0.2506 - val_accuracy: 0.9097 - val_loss: 0.2781\n",
      "Epoch 14/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9165 - loss: 0.2552 - val_accuracy: 0.9096 - val_loss: 0.2765\n",
      "Epoch 15/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9174 - loss: 0.2496 - val_accuracy: 0.9096 - val_loss: 0.2751\n",
      "Epoch 16/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9171 - loss: 0.2530 - val_accuracy: 0.9093 - val_loss: 0.2765\n",
      "Epoch 17/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9183 - loss: 0.2508 - val_accuracy: 0.9091 - val_loss: 0.2767\n",
      "Epoch 18/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9158 - loss: 0.2508 - val_accuracy: 0.9097 - val_loss: 0.2785\n",
      "Epoch 19/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9193 - loss: 0.2437 - val_accuracy: 0.9080 - val_loss: 0.2809\n",
      "Epoch 20/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9177 - loss: 0.2469 - val_accuracy: 0.9094 - val_loss: 0.2785\n",
      "Epoch 21/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9169 - loss: 0.2462 - val_accuracy: 0.9081 - val_loss: 0.2809\n",
      "Epoch 22/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9184 - loss: 0.2469 - val_accuracy: 0.9086 - val_loss: 0.2811\n",
      "Epoch 23/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9167 - loss: 0.2487 - val_accuracy: 0.9091 - val_loss: 0.2842\n",
      "Epoch 24/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9196 - loss: 0.2400 - val_accuracy: 0.9090 - val_loss: 0.2809\n",
      "Epoch 25/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9179 - loss: 0.2454 - val_accuracy: 0.9066 - val_loss: 0.2867\n",
      "Epoch 26/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9181 - loss: 0.2431 - val_accuracy: 0.9082 - val_loss: 0.2817\n",
      "Epoch 27/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9206 - loss: 0.2396 - val_accuracy: 0.9089 - val_loss: 0.2850\n",
      "Epoch 28/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9194 - loss: 0.2393 - val_accuracy: 0.9086 - val_loss: 0.2832\n",
      "Epoch 29/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9186 - loss: 0.2397 - val_accuracy: 0.9084 - val_loss: 0.2835\n",
      "Epoch 30/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9207 - loss: 0.2375 - val_accuracy: 0.9075 - val_loss: 0.2828\n",
      "Epoch 31/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9198 - loss: 0.2356 - val_accuracy: 0.9082 - val_loss: 0.2855\n",
      "Epoch 32/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9205 - loss: 0.2357 - val_accuracy: 0.9087 - val_loss: 0.2838\n",
      "Epoch 33/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9219 - loss: 0.2290 - val_accuracy: 0.9082 - val_loss: 0.2857\n",
      "Epoch 34/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9208 - loss: 0.2347 - val_accuracy: 0.9072 - val_loss: 0.2854\n",
      "Epoch 35/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9209 - loss: 0.2379 - val_accuracy: 0.9084 - val_loss: 0.2876\n",
      "Epoch 36/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9210 - loss: 0.2330 - val_accuracy: 0.9082 - val_loss: 0.2895\n",
      "Epoch 37/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9218 - loss: 0.2289 - val_accuracy: 0.9076 - val_loss: 0.2867\n",
      "Epoch 38/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9200 - loss: 0.2335 - val_accuracy: 0.9068 - val_loss: 0.2886\n",
      "Epoch 39/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9220 - loss: 0.2304 - val_accuracy: 0.9066 - val_loss: 0.2921\n",
      "Epoch 40/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9217 - loss: 0.2326 - val_accuracy: 0.9071 - val_loss: 0.2887\n",
      "Epoch 41/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9193 - loss: 0.2326 - val_accuracy: 0.9056 - val_loss: 0.2903\n",
      "Epoch 42/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9220 - loss: 0.2303 - val_accuracy: 0.9070 - val_loss: 0.2904\n",
      "Epoch 43/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9235 - loss: 0.2292 - val_accuracy: 0.9066 - val_loss: 0.2905\n",
      "Epoch 44/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9196 - loss: 0.2331 - val_accuracy: 0.9069 - val_loss: 0.2947\n",
      "Epoch 45/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9205 - loss: 0.2313 - val_accuracy: 0.9068 - val_loss: 0.2910\n",
      "Epoch 46/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9215 - loss: 0.2320 - val_accuracy: 0.9071 - val_loss: 0.2908\n",
      "Epoch 47/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9212 - loss: 0.2320 - val_accuracy: 0.9078 - val_loss: 0.2959\n",
      "Epoch 48/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9206 - loss: 0.2301 - val_accuracy: 0.9059 - val_loss: 0.2990\n",
      "Epoch 49/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9219 - loss: 0.2290 - val_accuracy: 0.9068 - val_loss: 0.2936\n",
      "Epoch 50/50\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9217 - loss: 0.2254 - val_accuracy: 0.9064 - val_loss: 0.2964\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n"
     ]
    }
   ],
   "source": [
    "# Train Neural Network\n",
    "nn_model = create_neural_network(X_train_combined.shape[1], len(np.unique(y_train_encoded)))\n",
    "trained_nn, nn_result, y_pred_nn = train_and_evaluate_model(\n",
    "    nn_model, 'Neural Network', X_train_combined, X_test_combined, y_train_encoded, y_test_encoded\n",
    ")\n",
    "trained_models['Neural Network'] = trained_nn\n",
    "results_df = pd.concat([results_df, pd.DataFrame([nn_result])], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8be32f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save neural network and update size\n",
    "trained_nn.save('temp_nn_model.h5')\n",
    "nn_size = os.path.getsize('temp_nn_model.h5') / (1024 * 1024)\n",
    "os.remove('temp_nn_model.h5')\n",
    "results_df.loc[results_df['model_name'] == 'Neural Network', 'model_size_mb'] = nn_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5ae5d716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SAVING RESULTS ===\n",
      "Best model: Logistic Regression with accuracy 0.9114\n",
      "Saved: saved_models/best_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Step 15: Save Best Model and Results\n",
    "print(\"\\n=== SAVING RESULTS ===\")\n",
    "best_model_row = results_df.loc[results_df['accuracy'].idxmax()]\n",
    "best_model_name = best_model_row['model_name']\n",
    "best_model = trained_models[best_model_name]\n",
    "\n",
    "print(f\"Best model: {best_model_name} with accuracy {best_model_row['accuracy']:.4f}\")\n",
    "\n",
    "# Save the best model\n",
    "if best_model_name == 'Neural Network':\n",
    "    best_model.save('saved_models/best_model_neural_network.h5')\n",
    "    print(\"Saved: saved_models/best_model_neural_network.h5\")\n",
    "else:\n",
    "    joblib.dump(best_model, 'saved_models/best_model.pkl')\n",
    "    print(\"Saved: saved_models/best_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bedc386",
   "metadata": {},
   "source": [
    "### Step 9: Save all trained models along with best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3b08b111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all models\n",
    "for model_name, model in trained_models.items():\n",
    "    if model_name != 'Neural Network':\n",
    "        joblib.dump(model, f'saved_models/{model_name.replace(\" \", \"_\").lower()}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0833374f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: model_evaluation_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Save results to CSV\n",
    "results_df.to_csv('data/model_evaluation_results.csv', index=False)\n",
    "print(\"Saved: model_evaluation_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d380120",
   "metadata": {},
   "source": [
    "### Step 10: Save Complete Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76c11d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: saved_models/training_config.json\n",
      "\n",
      "=== TRAINING COMPLETE ===\n",
      "Files created:\n",
      "- synthetic_insurance_data_with_tiers.csv\n",
      "- model_evaluation_results.csv\n",
      "- saved_models/ (directory with all preprocessing objects and models)\n",
      "- model_accuracy_comparison.png\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "config = {\n",
    "    'feature_columns': numerical_cols + categorical_cols + ['Processed_Note'],\n",
    "    'target_column': 'Tier',\n",
    "    'preprocessing_steps': {\n",
    "        'structured_preprocessor': 'saved_models/structured_preprocessor.pkl',\n",
    "        'text_preprocessor': 'saved_models/text_preprocessor.pkl',\n",
    "        'label_encoder': 'saved_models/label_encoder.pkl'\n",
    "    },\n",
    "    'best_model': best_model_name,\n",
    "    'best_accuracy': best_model_row['accuracy'],\n",
    "    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "}\n",
    "\n",
    "with open('saved_models/training_config.json', 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(\"Saved: saved_models/training_config.json\")\n",
    "print(\"\\n=== TRAINING COMPLETE ===\")\n",
    "print(\"Files created:\")\n",
    "print(\"- data/synthetic_insurance_data.csv\")\n",
    "print(\"- data/model_evaluation_results.csv\")\n",
    "print(\"- saved_models/ (directory with all trained models)\")\n",
    "print(\"- artifacts/ (directory with all preprocessing objects)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bd7cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "542a0a9d",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bc1fc352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[41, 'Male', 29.0, 1, 1, '1-2 Year', 'No', 39136.0, 275],\n",
       "       [76, 'Male', 33.0, 1, 1, '1-2 Year', 'No', 29653.0, 109],\n",
       "       [23, 'Female', 18.0, 1, 0, '< 1 Year', 'Yes', 40053.0, 282],\n",
       "       [49, 'Male', 8.0, 1, 1, '1-2 Year', 'No', 42977.0, 221],\n",
       "       [26, 'Male', 41.0, 1, 1, '< 1 Year', 'No', 31040.0, 114]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_structured[:5].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d29c3c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gold', 'Bronze', 'Gold', 'Silver', 'Silver']\n",
       "Categories (3, object): ['Bronze' < 'Silver' < 'Gold']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f19a1254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['respond bundle offer', 'respond generic query specific interest',\n",
       "       'engage live chat minute discuss vehicle coverage',\n",
       "       'profile show low engagement score avoid proactive outreach',\n",
       "       'customer browse agent profile prefer personalized service'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_text[:5].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948f9723",
   "metadata": {},
   "outputs": [],
   "source": [
    "text= [\n",
    "    # Gold\n",
    "    \"Customer requested a callback to discuss bundling home and vehicle insurance. Strong cross-sell potential.\",\n",
    "    \"Attended recent webinar on premium vehicle coverage. Asked multiple questions. Ready for conversion.\",\n",
    "    \"Referred two friends for vehicle insurance. Highly engaged and influential.\",\n",
    "    \"Downloaded comparison chart for premium plans. Wants to upgrade existing policy.\",\n",
    "\n",
    "\n",
    "    # Silver\n",
    "    \"Customer clicked on ad but did not proceed. Mild interest.\",\n",
    "    \"Asked about policy duration. Needs clarity before committing.\",\n",
    "    \"Customer has mid-tier health plan. Vehicle insurance could be next.\",\n",
    "    \"Opened email but didn‚Äôt click. Passive engagement.\",\n",
    "    \"Customer asked about EMI options. Needs affordability pitch.\",\n",
    "\n",
    "\n",
    "    # Bronze\n",
    "    \"Customer ignored multiple outreach attempts. Low engagement.\",\n",
    "    \"Profile shows minimal digital activity. Hard to reach.\",\n",
    "    \"Customer unsubscribed from marketing emails. Respect preferences.\",\n",
    "    \"Only visited homepage. No product interaction.\",\n",
    "    \"Customer has outdated contact info. Needs verification.\",\n",
    "    \n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
